{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8ca5d10e",
      "metadata": {},
      "source": [
        "front to back RAG implementation using lagchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c09d1f4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1bf65d4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "PATH = './docs'\n",
        "LLM_KEY = os.getenv(\"LLM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1b97a0a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 0: \n",
            "\n",
            "arXiv:2302.11382v1  [cs.SE]  21 Feb 2023\n",
            "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT\n",
            "Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos O lea, Henry Gilbert,\n",
            "Ashraf Elnashar, Jesse Spencer-Smith, and Douglas C. Schmi dt\n",
            "Department of Computer Science\n",
            "V anderbilt University, T ennessee\n",
            "Nashville, TN, USA\n",
            "{jules.white, quchen.fu, george.s.hays, michael.sandbor n, carlos.olea, henry.gilbert,\n",
            "ashraf.elnashar, jesse.spencer-smith, douglas.c.schmi dt}@vanderbilt.edu\n",
            "Abstract—Prompt engineering is an increasingly important\n",
            "skill set needed to converse effectively with large languag e models\n",
            "(LLMs), such as ChatGPT. Prompts are instructions given to a n\n",
            "LLM to enforce rules, automate processes, and ensure speciﬁ c\n",
            "qualities (and quantities) of generated output. Prompts ar e also\n",
            "a form of programming that can customize the outputs and\n",
            "interactions with an LLM.\n",
            "This paper describes a catalog of prompt engineering tech- \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 0: \n",
            "\n",
            "niques presented in pattern form that have been applied to so lve\n",
            "common problems when conversing with LLMs. Prompt patterns\n",
            "are a knowledge transfer method analogous to software patte rns\n",
            "since they provide reusable solutions to common problems fa ced\n",
            "in a particular context, i.e., output generation and intera ction\n",
            "when working with LLMs.\n",
            "This paper provides the following contributions to researc h on\n",
            "prompt engineering that apply LLMs to automate software de-\n",
            "velopment tasks. First, it provides a framework for documen ting\n",
            "patterns for structuring prompts to solve a range of problem s\n",
            "so that they can be adapted to different domains. Second, it\n",
            "presents a catalog of patterns that have been applied succes sfully\n",
            "to improve the outputs of LLM conversations. Third, it expla ins\n",
            "how prompts can be built from multiple patterns and illustra tes\n",
            "prompt patterns that beneﬁt from combination with other pro mpt\n",
            "patterns.\n",
            "Index Terms—large language models, prompt patterns, prompt\n",
            "engineering \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 0: \n",
            "\n",
            "I. I NTRODUCTION\n",
            "Conversational large language models (LLMs) [1], such as\n",
            "ChatGPT [2], have generated immense interest in a range\n",
            "of domains for tasks ranging from answering questions on\n",
            "medical licensing exams [3] to generating code snippets. Th is\n",
            "paper focuses on enhancing the application of LLMs in severa l\n",
            "domains, such as helping developers code effectively and\n",
            "efﬁciently with unfamiliar APIs or allowing students to acq uire\n",
            "new coding skills and techniques.\n",
            "LLMs are particularly promising in domains where humans\n",
            "and AI tools work together as trustworthy collaborators to\n",
            "more rapidly and reliably evolve software-reliant systems [4].\n",
            "For example, LLMs are being integrated directly into softwa re\n",
            "tools, such as Github’s Co-Pilot [5]–[7] and included in int e-\n",
            "grated development environments (IDEs), such as IntelliJ [ 8]\n",
            "and Visual Studio Code, thereby allowing software teams to\n",
            "access these tools directly from their preferred IDE. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 0: \n",
            "\n",
            "A prompt [9] is a set of instructions provided to an\n",
            "LLM that programs the LLM by customizing it and/or en-\n",
            "hancing or reﬁning its capabilities . A prompt can inﬂuence\n",
            "subsequent interactions with—and output generated from—a n\n",
            "LLM by providing speciﬁc rules and guidelines for an LLM\n",
            "conversation with a set of initial rules. In particular, a pr ompt\n",
            "sets the context for the conversation and tells the LLM what\n",
            "information is important and what the desired output form an d\n",
            "content should be.\n",
            "For example, a prompt could specify that an LLM should\n",
            "only generate code that follows a certain coding style or\n",
            "programming paradigm. Likewise, it could specify that an\n",
            "LLM should ﬂag certain keywords or phrases in a generated\n",
            "document and provide additional information related to tho se\n",
            "keywords. By introducing these guidelines, prompts facili tate\n",
            "more structured and nuanced outputs to aid a large variety of\n",
            "software engineering tasks in the context of LLMs. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 0: \n",
            "\n",
            "Prompt engineering is the means by which LLMs are\n",
            "programmed via prompts. To demonstrate the power of\n",
            "prompt engineering, we provide the following prompt:\n",
            "Prompt: “From now on, I would like you to ask me\n",
            "questions to deploy a Python application to AWS.\n",
            "When you have enough information to deploy the\n",
            "application, create a Python script to automate the\n",
            "deployment.”\n",
            "This example prompt causes ChatGPT to begin asking the\n",
            "user questions about their software application. ChatGPT w ill\n",
            "drive the question-asking process until it reaches a point w here\n",
            "it has sufﬁcient information to generate a Python script tha t\n",
            "automates deployment. This example demonstrates the pro-\n",
            "gramming potential of prompts beyond conventional “genera te\n",
            "a method that does X” style prompts or “answer this quiz\n",
            "question”.\n",
            "Moreover, prompts can be engineered to program an LLM\n",
            "to accomplish much more than simply dictating the output typ e\n",
            "or ﬁltering the information provided to the model. With the \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 0: \n",
            "\n",
            "right prompt, it is possible to create entirely new interact ion\n",
            "paradigms, such as having an LLM generate and give a quiz\n",
            "associated with a software engineering concept or tool, or\n",
            "even simulate a Linux terminal window. Moreover, prompts\n",
            "have the potential for self-adaptation, suggesting other p rompts\n",
            "to gather additional information or generate related artif acts.\n",
            "These advanced capabilities of prompts highlight the impor -\n",
            "tance of engineering them to provide value beyond simple tex t\n",
            "or code generation.\n",
            "Prompt patterns are essential to effective prompt engi-\n",
            "neering. A key contribution of this paper is the introduction\n",
            "of prompt patterns to document successful approaches for \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 1: \n",
            "\n",
            "systematically engineering different output and interact ion\n",
            "goals when working with conversational LLMs. We focus\n",
            "largely on engineering domain-independent prompt pattern s\n",
            "and introduce a catalog of essential prompt patterns to solv e\n",
            "problems ranging from production of visualizations and cod e\n",
            "artifacts to automation of output steps that help fact check\n",
            "outputs.\n",
            "The remainder of this paper is organized as follows: Sec-\n",
            "tion II introduces prompt patterns and compares these patte rns\n",
            "to well-known software patterns [10]; Section III describe s\n",
            "16 prompt patterns that have been applied to solve common\n",
            "problems in the domain of conversational LLM interaction an d\n",
            "output generation for automating software development tas ks;\n",
            "Section IV discusses related work; and Section V presents\n",
            "concluding remarks and lessons learned.\n",
            "II. C OMPARING SOFTWARE PATTERNS\n",
            "WITH PROMPT PATTERNS\n",
            "The quality of the output(s) generated by a conversational \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 1: \n",
            "\n",
            "LLM is directly related to the quality of the prompts provide d\n",
            "by the user. As discussed in Section I, the prompts given to\n",
            "a conversational LLM can be used to program interactions\n",
            "between a user and an LLM to better solve a variety of\n",
            "problems. One contribution of this paper is the framework it\n",
            "provides to document patterns that structure prompts to sol ve\n",
            "a range of software tasks that can be adapted to different\n",
            "domains.\n",
            "This framework is useful since it focuses on codifying\n",
            "patterns that can be applied to help users better interact\n",
            "with conversational LLMs in a variety of contexts, rather\n",
            "than simply discussing interesting examples or domain-spe ciﬁc\n",
            "prompts. Codifying this knowledge in pattern form enhances\n",
            "reuse and transferability to other contexts and domains whe re\n",
            "users face similar—but not identical—problems.\n",
            "The topic of knowledge transfer has been studied exten-\n",
            "sively in the software patterns literature [10], [11] at mul tiple \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 1: \n",
            "\n",
            "levels, e.g., design, architectural, and analysis. This paper\n",
            "applies a variant of a familiar pattern form as the basis of\n",
            "our prompt engineering approach. Since prompts are a form\n",
            "of programming, it is natural to document them in pattern\n",
            "form.\n",
            "A. Overview of Software Patterns\n",
            "A software pattern provides a reusable solution to a recur-\n",
            "ring problem within a particular context [10]. Documenting\n",
            "software patterns concisely conveys (and generalizes) fro m\n",
            "speciﬁc problems being addressed to identify important for ces\n",
            "and/or requirements that should be resolved and/or address ed\n",
            "in successful solutions.\n",
            "A pattern form also includes guidance on how to implement\n",
            "the pattern, as well as information on the trade-offs and\n",
            "considerations to take into account when implementing a\n",
            "pattern. Moreover, example applications of the pattern are\n",
            "often provided to further showcase the pattern’s utility in\n",
            "practice. Software patterns are typically documented in a \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 1: \n",
            "\n",
            "stylized form to facilitate their use and understanding, su ch\n",
            "as:\n",
            "• A name and classiﬁcation . Each pattern has a name that\n",
            "identiﬁes the pattern and should be used consistently. A\n",
            "classiﬁcation groups patterns into broad categories, such\n",
            "as creational, structural, or behavioral.\n",
            "• The intent concisely conveys the purpose the pattern is\n",
            "intended to achieve.\n",
            "• The motivation documents the underlying problem the\n",
            "pattern is meant to solve and the importance of the\n",
            "problem.\n",
            "• The structure and participants . The structure describes\n",
            "the different pattern participants (such as classes and\n",
            "objects) and how they collaborate to form a generalized\n",
            "solution.\n",
            "• Example code concretely maps the pattern to some\n",
            "underlying programming language(s) and aids developers\n",
            "in gaining greater insight into how that pattern can be\n",
            "applied effectively.\n",
            "• Consequences summarize the pros and cons of applying\n",
            "the pattern in practice.\n",
            "B. Overview of Prompt Patterns \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 1: \n",
            "\n",
            "Prompt patterns are similar to software patterns in that the y\n",
            "offer reusable solutions to speciﬁc problems. They focus mo re\n",
            "speciﬁcally, however, on the context of output generation f rom\n",
            "large-scale language models (LLMs), such as ChatGPT. Just\n",
            "as software patterns provide a codiﬁed approach to solving\n",
            "common software development challenges, prompt patterns\n",
            "provide a codiﬁed approach to customizing the output and\n",
            "interactions of LLMs.\n",
            "By documenting and leveraging prompt patterns in the\n",
            "context of automating software development tasks, individ ual\n",
            "users and teams can enforce constraints on the generated\n",
            "output, ensure that relevant information is included, and\n",
            "change the format of interaction with the LLM to better\n",
            "solve problems they face. Prompt patterns can be viewed as a\n",
            "corollary to the broad corpus of general software patterns, just\n",
            "adapted to the more speciﬁc context of LLM output generation .\n",
            "Prompt patterns follow a similar format to classic software \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 1: \n",
            "\n",
            "patterns, with slight modiﬁcations to match the context of\n",
            "output generation with LLMs. 1 Each of the analogous sections\n",
            "for the prompt pattern form used in this paper is summarized\n",
            "below:\n",
            "• A name and classiﬁcation . The prompt pattern name\n",
            "uniquely identiﬁes the pattern and ideally indicates the\n",
            "problem that is being addressed. For the classiﬁcation,\n",
            "we have developed a series of initial categories of pattern\n",
            "types, which are summarized in Table I and include\n",
            "Output Customization , Error Identiﬁcation , Prompt\n",
            "Improvement, Interaction, and Context Control .\n",
            "• The intent and context describes the problem the prompt\n",
            "pattern solves and the goals it achieves. The problem\n",
            "1The most direct translation of software pattern structure t o prompt patterns\n",
            "is the naming, intent, motivation, and sample code. The stru cture and\n",
            "classiﬁcation, however, although named similarly, requir e more adaptation. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 2: \n",
            "\n",
            "should ideally be independent of any domain, though\n",
            "domain-speciﬁc patterns may also be documented with\n",
            "an appropriate discussion of the context where the pattern\n",
            "applies.\n",
            "• The motivation provides the rationale for the problem\n",
            "and explains why solving it is important. The motivation\n",
            "is explained in the context of users interacting with a\n",
            "conversational LLM and how it can improve upon users\n",
            "informally prompting the LLM in one or more circum-\n",
            "stances. Speciﬁc circumstances where the improvements\n",
            "are expected are documented.\n",
            "• The structure and key ideas . The structure describes\n",
            "the fundamental contextual information, as a series of\n",
            "key ideas, that the prompt pattern provides to the LLM.\n",
            "These ideas are similar to “participants” in a software pat-\n",
            "tern. The contextual information may be communicated\n",
            "through varying wording (just as a software pattern can\n",
            "have variations in how it is realized in code), but should\n",
            "have fundamental pieces of information that form a core \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 2: \n",
            "\n",
            "element of the pattern.\n",
            "• Example implementation demonstrates how the prompt\n",
            "pattern is worded in practice.\n",
            "• Consequences summarize the pros and cons of applying\n",
            "the pattern and may provide guidance on how to adapt\n",
            "the prompt to different contexts.\n",
            "C. Evaluating Means for Deﬁning a Prompt Pattern’s Struc-\n",
            "ture and Ideas\n",
            "In software patterns, the structure and participants are\n",
            "normally deﬁned in terms of UML diagrams, such as structure\n",
            "diagrams and/or interaction diagrams. These UML diagrams\n",
            "explain what the participants of the pattern are and how they\n",
            "interact to solve the problem. In prompt patterns, somethin g\n",
            "analogous is needed, though UML may not be an appro-\n",
            "priate structural documentation approach since it is inten ded\n",
            "to describe software structures, as opposed to the ideas to\n",
            "communicate in a prompt.\n",
            "Several possible approaches could be used, ranging from di-\n",
            "agrams to deﬁning grammars for a prompt language. Although \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 2: \n",
            "\n",
            "grammars may seem attractive due to their formal nature, the y\n",
            "also incur the following challenges:\n",
            "• The goal of prompts is to communicate knowledge in a\n",
            "clear and concise way to conversation LLM users, who\n",
            "may or may not be computer scientists or programmers.\n",
            "As a community, we should strive to create an approach-\n",
            "able format that communicates knowledge clearly to a\n",
            "diverse target audience.\n",
            "• It is possible to phrase a prompt in many different ways.\n",
            "It is hard, however, to deﬁne a grammar that accurately\n",
            "and completely expresses all the nuanced ways that\n",
            "components of a prompt could be expressed in text or\n",
            "symbols.\n",
            "• Prompts fundamentally convey ideas to a conversational\n",
            "LLM and are not simply the production of tokens for\n",
            "input. In particular, an idea built into a prompt pattern\n",
            "can be communicated in many ways and its expression\n",
            "should be at a higher-level than the underlying tokens\n",
            "representing the idea.\n",
            "• It is possible to program an LLM to introduce novel \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 2: \n",
            "\n",
            "semantics for statements and words that create new ways\n",
            "for communicating an idea. In contrast, grammars may\n",
            "not easily represent ideas that can be expressed through\n",
            "completely new symbology or languages that the gram-\n",
            "mar designer was not aware of.\n",
            "D. A W ay F orward: Fundamental Contextual Statements\n",
            "An open research question, therefore, is what approach is\n",
            "more effective than formal grammars for describing prompt\n",
            "pattern structure and ideas. We propose the concept of funda-\n",
            "mental contextual statements , which are written descriptions\n",
            "of the important ideas to communicate in a prompt to an LLM.\n",
            "An idea can be rewritten and expressed in arbitrary ways base d\n",
            "on user needs and experience. The key ideas to communicate,\n",
            "however, are presented to the user as a series of simple, but\n",
            "fundamental, statements.\n",
            "One beneﬁt of adopting and applying the fundamental con-\n",
            "textual statements approach is that it is intentionally int uitive \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 2: \n",
            "\n",
            "to users. In particular, we expect users will understand how to\n",
            "express and adapt the statements in a contextually appropri ate\n",
            "way for their domain. Moreover, since the underlying ideas o f\n",
            "the prompt are captured, these same ideas can be expressed\n",
            "by the user in alternate symbology or wording that has been\n",
            "introduced to the LLM using patterns, such as the Meta\n",
            "Language Creation pattern presented in Section III-B.\n",
            "Our ultimate goal is to enhance prompt engineering by\n",
            "providing a framework for designing prompts that can be\n",
            "reused and/or adapted to other LLMs in the same way that\n",
            "software patterns can be implemented in different program-\n",
            "ming languages and platforms. For the purposes of this paper ,\n",
            "however, all prompts were tested with ChatGPT [12] using the\n",
            "ChatGPT+ service. We use ChatGPT as the LLM for all exam-\n",
            "ples presented in this paper due to its widespread availabil ity\n",
            "and popularity. These examples were documented through a \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 2: \n",
            "\n",
            "combination of exploring the corpus of community-posted\n",
            "prompts on the Internet and independent prompt creation fro m\n",
            "our use of ChatGPT to automating software development\n",
            "tasks.\n",
            "III. A C ATALOG OF PROMPT PATTERNS\n",
            "FOR CONVERSATIONAL LLM S\n",
            "This section presents our catalog of prompt patterns that\n",
            "have been applied to solve common problems in the domain\n",
            "of conversational LLM interaction and output generation fo r\n",
            "automating software tasks. Each prompt pattern is accompa-\n",
            "nied by concrete implementation samples and examples with\n",
            "and without the prompt.\n",
            "A. Summary of the Prompt Pattern Catalog\n",
            "The classiﬁcation of prompt patterns is an important consid -\n",
            "eration in documenting the patterns. Table I outlines the in itial\n",
            "classiﬁcations for the catalog of prompt patterns we identi ﬁed\n",
            "in our work with ChatGPT thus far. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 3: \n",
            "\n",
            "TABLE I\n",
            "CLASSIFYING PROMPT PATTERNS\n",
            "Pattern Category Prompt Pattern\n",
            "Input Semantics Meta Language Creation\n",
            "Output Output Automater\n",
            "Customization Persona\n",
            "Visualization Generator\n",
            "Recipe\n",
            "Template\n",
            "Error Identiﬁcation Fact Check List\n",
            "Reﬂection\n",
            "Prompt Question Reﬁnement\n",
            "Improvement Alternative Approaches\n",
            "Cognitive V eriﬁer\n",
            "Refusal Breaker\n",
            "Interaction Flipped Interaction\n",
            "Game Play\n",
            "Inﬁnite Generation\n",
            "Context Control Context Manager\n",
            "As shown in this table, there are ﬁve categories of prompt\n",
            "patterns in our classiﬁcation framework: Input Semantics ,\n",
            "Output Customization , Error Identiﬁcation , Prompt Im-\n",
            "provement, and Interaction, each of which is summarized\n",
            "below.\n",
            "The Input Semantics category deals with how an LLM\n",
            "understands the input and how it translates the input into\n",
            "something it can use to generate output. This category in-\n",
            "cludes the Meta Language Creation pattern, which focuses on\n",
            "creating a custom language for the LLM to understand. This \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 3: \n",
            "\n",
            "pattern is useful when the default input language is ill-sui ted\n",
            "for expressing ideas the user wants to convey to the LLM.\n",
            "The Output Customization category focuses on constrain-\n",
            "ing or tailoring the types, formats, structure, or other pro perties\n",
            "of the output generated by the LLM. The prompt patterns in\n",
            "this category include Output Automater , Persona, Visualiza-\n",
            "tion Generator , Recipe, and T emplate patterns. The Output\n",
            "Automater pattern allows the user to create scripts that can\n",
            "automate any tasks the LLM output suggests the user should\n",
            "perform. The Persona pattern gives the LLM a persona or role\n",
            "to play when generating output. The Visualization Generator\n",
            "pattern allows the user to generate visualizations by produ cing\n",
            "textual outputs that can be fed to other tools, such as other\n",
            "AI-based image generators, like DALL-E [13]. The Recipe\n",
            "pattern allows the user to obtain a sequence of steps or actio ns\n",
            "to realize a stated end result, possibly with partially know n \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 3: \n",
            "\n",
            "information or constraints. The T emplate pattern allows the\n",
            "user to specify a template for the output, which the LLM ﬁlls\n",
            "in with content.\n",
            "The Error Identiﬁcation category focuses on identifying\n",
            "and resolving errors in the output generated by the LLM. This\n",
            "category includes the Fact Check List and Reﬂection patterns.\n",
            "The Fact Check List pattern requires the LLM to generate a\n",
            "list of facts the output depends on that should be fact-check ed.\n",
            "The Reﬂection pattern requires the LLM to introspect on its\n",
            "output and identify any errors.\n",
            "The Prompt Improvement category focuses on improving\n",
            "the quality of the input and output. This category includes\n",
            "the Question Reﬁnement , Alternative Approaches , Cognitive\n",
            "V eriﬁer, and Refusal Breaker patterns. The Question Reﬁne-\n",
            "ment pattern ensures the LLM always suggests a better version\n",
            "of the user’s question. The Alternative Approaches pattern\n",
            "requires the LLM to suggest alternative ways of accomplishi ng \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 3: \n",
            "\n",
            "a user-speciﬁed task. The Cognitive V eriﬁer pattern instructs\n",
            "the LLM to automatically suggest a series of subquestions\n",
            "for the user to answer before combining the answers to the\n",
            "subquestions and producing an answer to the overall questio n.\n",
            "The Refusal Breaker pattern requires the LLM to automatically\n",
            "reword the user’s question when it refuses to produce an\n",
            "answer.\n",
            "The Interaction category focuses on the interaction be-\n",
            "tween the user and the LLM. This category includes the\n",
            "Flipped Interaction , Game Play , and Inﬁnite Generation pat-\n",
            "terns. The Flipped Interaction pattern requires the LLM to\n",
            "ask questions rather than generate output. The Game Play\n",
            "pattern requires the LLM to generate output in the form of\n",
            "a game. The Inﬁnite Generation pattern requires the LLM to\n",
            "generate output indeﬁnitely without the user having to reen ter\n",
            "the generator prompt each time.\n",
            "Finally, the Context Control category focuses on control-\n",
            "ling the contextual information in which the LLM operates. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 3: \n",
            "\n",
            "This category includes the Context Manager pattern, which\n",
            "allows the user to specify the context for the LLM’s output.\n",
            "The remainder of this section describes each of these prompt\n",
            "patterns using the pattern form discussed in Section II-B.\n",
            "B. The Meta Language Creation Pattern\n",
            "1) Intent and Context: During a conversation with an LLM,\n",
            "the user would like to create the prompt via an alternate\n",
            "language, such as a textual short-hand notation for graphs, a\n",
            "description of states and state transitions for a state mach ine, a\n",
            "set of commands for prompt automation, etc. The intent of thi s\n",
            "pattern is to explain the semantics of this alternative lang uage\n",
            "to the LLM so the user can write future prompts using this\n",
            "new language and its semantics.\n",
            "2) Motivation: Many problems, structures, or other ideas\n",
            "communicated in a prompt may be more concisely, unam-\n",
            "biguously, or clearly expressed in a language other than\n",
            "English (or whatever conventional human language is used \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 3: \n",
            "\n",
            "to interact with an LLM). To produce output based on an\n",
            "alternative language, however, an LLM needs to understand\n",
            "the language’s semantics.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "When I say X, I mean Y (or would like you to do Y) \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 4: \n",
            "\n",
            "The key structure of this pattern involves explaining the\n",
            "meaning of one or more symbols, words, or statements to\n",
            "the LLM so it uses the provided semantics for the ensuing\n",
            "conversation. This description can take the form of a simple\n",
            "translation, such as “X” means “Y”. The description can also\n",
            "take more complex forms that deﬁne a series of commands\n",
            "and their semantics, such as “when I say X, I want you to do\n",
            "”. In this case, “X” is henceforth bound to the semantics of\n",
            "“take action”.\n",
            "4) Example Implementation: The key to successfully using\n",
            "the Meta Language Creation pattern is developing an unam-\n",
            "biguous notation or shorthand, such as the following:\n",
            "“From now on, whenever I type two identiﬁers\n",
            "separated by a “ →”, I am describing a graph. For\n",
            "example, “a → b” is describing a graph with nodes\n",
            "“a” and “b” and an edge between them. If I separate\n",
            "identiﬁers by “-[w:2, z:3] →”, I am adding properties\n",
            "of the edge, such as a weight or label.” \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 4: \n",
            "\n",
            "This example of the Meta Language Creation pattern estab-\n",
            "lishes a standardized notation for describing graphs by deﬁ ning\n",
            "a convention for representing nodes and edges. Whenever the\n",
            "author types two identiﬁers separated by a “ →” symbol, it is\n",
            "an indication that a graph is being described. For example, i f\n",
            "the author types “a → b”, this indicates that a graph is being\n",
            "deﬁned with nodes “a” and “b”, and that there is an edge\n",
            "between them. This convention provides a clear and concise\n",
            "way to communicate the structure of a graph in written form.\n",
            "Moreover, the prompt goes on to specify that additional\n",
            "information about the edges, such as a weight or label, can\n",
            "be provided using the syntax “-[w:2, z:3] →”. This notation\n",
            "allows for the speciﬁcation of additional properties beyon d\n",
            "the basic structure of the graph. The speciﬁed properties ar e\n",
            "associated with the edge between the two nodes and can\n",
            "provide important context for the interpretation of the gra ph. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 4: \n",
            "\n",
            "This standardized notation for describing graphs can make i t\n",
            "easier to communicate graph structures and properties, whi ch\n",
            "may not be easy or are very verbose to describe as a series of\n",
            "sentences.\n",
            "5) Consequences: Although this pattern provides a pow-\n",
            "erful means to customize a user’s interaction with an LLM,\n",
            "it may create the potential for confusion within the LLM.\n",
            "As important as it is to clearly deﬁne the semantics of the\n",
            "language, it is also essential to ensure the language itself\n",
            "introduces no ambiguities that degrade the LLM’s performan ce\n",
            "or accuracy. For example, the prompt “whenever I separate\n",
            "two things by commas, it means that the ﬁrst thing precedes\n",
            "the second thing” will likely create signiﬁcant potential f or\n",
            "ambiguity and create the potential for unexpected semantic s\n",
            "if punctuation involving commas is used in the prompt.\n",
            "To showcase the potential for confusion, ChatGPT will\n",
            "warn the user and potentially be unable to perform a speciﬁc \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 4: \n",
            "\n",
            "mapping of a symbol or term to a new meaning. For example,\n",
            "if following prompt is given to ChatGPT\n",
            "“Whenever I say “a”, I am referring to Marie An-\n",
            "toinette.”\n",
            "it will respond that this prompt creates too much confusion\n",
            "as “a” is an indeﬁnite article and too commonly used, as shown\n",
            "below:\n",
            "“Referring to Marie Antoinette using “a” could\n",
            "potentially cause confusion, as “a” is an indeﬁnite\n",
            "article commonly used to refer to a noun that has\n",
            "not been mentioned before. It may be more clear\n",
            "to use her name, “Marie Antoinette”, or a pronoun\n",
            "such as “she” or “her” to refer to her. Moreover,\n",
            "using context to establish who you are referring to\n",
            "can also help avoid confusion in conversation.”\n",
            "In general, an LLM will perform better on data it was\n",
            "trained on. Therefore, when an existing notation is availab le—\n",
            "but may not be the dominant meaning—the Meta Language\n",
            "Creation pattern can provide context to scope the meaning of\n",
            "the symbol to improve the accurately and utility of the outpu t. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 4: \n",
            "\n",
            "For example, the symbol “ →” conveys slightly different infor-\n",
            "mation in graphs and propositional logic. The statement “p →\n",
            "q, q → p” may therefore make sense, but only if the LLM\n",
            "is given the appropriate context through a Meta Language\n",
            "Creation prompt.\n",
            "Although Meta Language Creation is a powerful pattern it\n",
            "must be used carefully, particularly when describing conce pts\n",
            "that may otherwise be hard to precisely or concisely describ e.\n",
            "These types of prompts are thus best used in completely\n",
            "new conversation sessions. Using a single meta-language-p er-\n",
            "conversation session may also be a best practice since it avo ids\n",
            "the potential for conﬂicting or unexpected semantics being\n",
            "applied to the conversation over time.\n",
            "C. The Output Automater Pattern\n",
            "1) Intent and Context: The intent of this pattern is to have\n",
            "the LLM generate a script or other automation artifact that c an\n",
            "automatically perform any steps it recommends taking as par t \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 4: \n",
            "\n",
            "of its output. The goal is to reduce the manual effort needed\n",
            "to implement any LLM output recommendations.\n",
            "2) Motivation: The output of an LLM is often a sequence\n",
            "of steps for the user to follow. For example, when asking an\n",
            "LLM to generate a Python conﬁguration script it may suggest\n",
            "a number of ﬁles to modify and changes to apply to each ﬁle.\n",
            "However, having users continually perform the manual steps\n",
            "dictated by LLM output is tedious and error-prone.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Whenever you produce an output that has at least one\n",
            "step to take and the following properties (alternatively,\n",
            "always do this)\n",
            "Produce an executable artifact of type X that will\n",
            "automate these steps\n",
            "The ﬁrst part of the pattern identiﬁes the situations under\n",
            "which automation should be generated. A simple approach\n",
            "is to state that the output includes at least two steps to\n",
            "take and that an automation artifact should be produced. The \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 5: \n",
            "\n",
            "scoping is up to the user, but helps prevent producing an\n",
            "output automation scripts in cases where running the output\n",
            "automation script will take more user effort than performin g\n",
            "the original steps produced in the output. The scope can be\n",
            "limited to outputs requiring more than a certain number of\n",
            "steps.\n",
            "The next part of this pattern provides a concrete statement\n",
            "of the type of output the LLM should output to perform the\n",
            "automation. For example, “produce a Python script” gives th e\n",
            "LLM a concrete understanding to translate the general steps\n",
            "into equivalent steps in Python. The automation artifact sh ould\n",
            "be concrete and must be something that the LLM associates\n",
            "with the action of “automating a sequence of steps”.\n",
            "4) Example Implementation: A sample of this prompt pat-\n",
            "tern applied to code snippets generated by the ChatGPT LLM\n",
            "is shown below:\n",
            "“From now on, whenever you generate code that\n",
            "spans more than one ﬁle, generate a Python script \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 5: \n",
            "\n",
            "that can be run to automatically create the speciﬁed\n",
            "ﬁles or make changes to existing ﬁles to insert the\n",
            "generated code.”\n",
            "This pattern is particularly effective in software enginee ring\n",
            "as a common task for software engineers using LLMs is to\n",
            "then copy/paste the outputs into multiple ﬁles. Some tools,\n",
            "such as Copilot, insert limited snippets directly into the s ection\n",
            "of code that the coder is working with, but tools, such as\n",
            "ChatGPT, do not provide these facilities. This automation t rick\n",
            "is also effective at creating scripts for running commands o n\n",
            "a terminal, automating cloud operations, or reorganizing ﬁ les\n",
            "on a ﬁle system.\n",
            "This pattern is a powerful complement for any system that\n",
            "can be computer controlled. The LLM can provide a set of\n",
            "steps that should be taken on the computer-controlled syste m\n",
            "and then the output can be translated into a script that allow s\n",
            "the computer controlling the system to automatically take\n",
            "the steps. This is a direct pathway to allowing LLMs, such \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 5: \n",
            "\n",
            "as ChatGPT, to integrate quality into—and to control—new\n",
            "computing systems that have a known scripting interface.\n",
            "5) Consequences: An important usage consideration of\n",
            "this pattern is that the automation artifact must be deﬁned\n",
            "concretely. Without a concrete meaning for how to “automate ”\n",
            "the steps, the LLM often states that it “can’t automate thing s”\n",
            "since that is beyond its capabilities. LLMs typically accep t\n",
            "requests to produce code, however, so the goal is to instruct the\n",
            "LLM to generate text/code, which can be executed to automate\n",
            "something. This subtle distinction in meaning is important to\n",
            "help an LLM disambiguate the prompt meaning.\n",
            "One caveat of the Output Automater pattern is the LLM\n",
            "needs sufﬁcient conversational context to generate an auto ma-\n",
            "tion artifact that is functional in the target context, such as\n",
            "the ﬁle system of a project on a Mac vs. Windows computer.\n",
            "This pattern works best when the full context needed for the \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 5: \n",
            "\n",
            "automation is contained within the conversation, e.g., when\n",
            "a software application is generated from scratch using the\n",
            "conversation and all actions on the local ﬁle system are\n",
            "performed using a sequence of generated automation artifac ts\n",
            "rather than manual actions unknown to the LLM. Alternativel y,\n",
            "self-contained sequences of steps work well, such as “how do\n",
            "I ﬁnd the list of open ports on my Mac computer”.\n",
            "In some cases, the LLM may produce a long output with\n",
            "multiple steps and not include an automation artifact. This\n",
            "omission may arise for various reasons, including exceedin g\n",
            "the output length limitation the LLM supports. A simple\n",
            "workaround for this situation is to remind the LLM via a\n",
            "follow-on prompt, such as “But you didn’t automate it”, whic h\n",
            "provides the context that the automation artifact was omitt ed\n",
            "and should be generated.\n",
            "At this point in the evolution of LLMs, the Output Auto-\n",
            "mater pattern is best employed by users who can read and \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 5: \n",
            "\n",
            "understand the generated automation artifact. LLMs can (an d\n",
            "do) produce inaccuracies in their output, so blindly accept ing\n",
            "and executing an automation artifact carries signiﬁcant ri sk.\n",
            "Although this pattern may alleviate the user from performin g\n",
            "certain manual steps, it does not alleviate their responsib ility\n",
            "to understand the actions they undertake using the output.\n",
            "When users execute automation scripts, therefore they assu me\n",
            "responsibility for the outcomes.\n",
            "D. The Flipped Interaction Pattern\n",
            "1) Intent and Context: Y ou want the LLM to ask questions\n",
            "to obtain the information it needs to perform some tasks.\n",
            "Rather than the user driving the conversation, therefore, y ou\n",
            "want the LLM to drive the conversation to focus it on\n",
            "achieving a speciﬁc goal. For example, you may want the\n",
            "LLM to give you a quick quiz or automatically ask questions\n",
            "until it has sufﬁcient information to generate a deployment\n",
            "script for your application to a particular cloud environme nt. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 5: \n",
            "\n",
            "2) Motivation: Rather than having the user drives a con-\n",
            "versation, an LLM often has knowledge it can use to more\n",
            "accurately obtain information from the user. The goal of the\n",
            "Flipped Interaction pattern is to ﬂip the interaction ﬂow so the\n",
            "LLM asks the user questions to achieve some desired goal. The\n",
            "LLM can often better select the format, number, and content\n",
            "of the interactions to ensure that the goal is reached faster ,\n",
            "more accurately, and/or by using knowledge the user may not\n",
            "(initially) possess.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "I would like you to ask me questions to achieve X\n",
            "Y ou should ask questions until this condition is met or\n",
            "to achieve this goal (alternatively, forever)\n",
            "(Optional) ask me the questions one at a time, two at\n",
            "a time, etc.\n",
            "A prompt for a ﬂipped interaction should always specify the\n",
            "goal of the interaction. The ﬁrst idea ( i.e., you want the LLM to \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 5: \n",
            "\n",
            "ask questions to achieve a goal) communicates this goal to th e\n",
            "LLM. Equally important is that the questions should focus on a\n",
            "particular topic or outcome. By providing the goal, the LLM\n",
            "can understand what it is trying to accomplish through the\n",
            "interaction and tailor its questions accordingly. This “in version \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 6: \n",
            "\n",
            "of control” enables more focused and efﬁcient interaction s ince\n",
            "the LLM will only ask questions that it deems relevant to\n",
            "achieving the speciﬁed goal.\n",
            "The second idea provides the context for how long the in-\n",
            "teraction should occur. A ﬂipped interaction can be termina ted\n",
            "with a response like “stop asking questions”. It is often bet ter,\n",
            "however, to scope the interaction to a reasonable length or\n",
            "only as far as is needed to reach the goal. This goal can be\n",
            "surprisingly open-ended and the LLM will continue to work\n",
            "towards the goal by asking questions, as is the case in the\n",
            "example of ”until you have enough information to generate a\n",
            "Python script”.\n",
            "By default, the LLM is likely to generate multiple questions\n",
            "per iteration. The third idea is completely optional, but ca n\n",
            "improve usability by limiting (or expanding) the number of\n",
            "questions that the LLM generates per cycle. If a precise\n",
            "number/format for the questioning is not speciﬁed, the ques - \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 6: \n",
            "\n",
            "tioning will be semi-random and may lead to one-at-a-time\n",
            "questions or ten-at-a-time questions. The prompt can thus b e\n",
            "tailored to include the number of questions asked at a time,\n",
            "the order of the questions, and any other formatting/orderi ng\n",
            "considerations to facilitate user interaction.\n",
            "4) Example Implementation: A sample prompt for a ﬂipped\n",
            "interaction is shown below:\n",
            "“From now on, I would like you to ask me questions\n",
            "to deploy a Python application to AWS. When you\n",
            "have enough information to deploy the application,\n",
            "create a Python script to automate the deployment.”\n",
            "In general, the more speciﬁc the prompt regarding the\n",
            "constraints and information to collect, the better the outc ome.\n",
            "For instance, the example prompt above could provide a menu\n",
            "of possible AWS services (such as Lambda, EC2, etc.) with\n",
            "which to deploy the application. In other cases, the LLM may\n",
            "be permitted to simply make appropriate choices on its own fo r \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 6: \n",
            "\n",
            "things that the user doesn’t explicitly make decisions abou t.\n",
            "One limitation of this prompt is that, once other contextual\n",
            "information is provided regarding the task, it may require\n",
            "experimentation with the precise phrasing to get the LLM to\n",
            "ask the questions in the appropriate number and ﬂow to best\n",
            "suit the task, such as asking multiple questions at once vers us\n",
            "one question at a time.\n",
            "5) Consequences: One consideration when designing the\n",
            "prompt is how much to dictate to the LLM regarding what\n",
            "information to collect prior to termination. In the example\n",
            "above, the ﬂipped interaction is open-ended and can vary sig -\n",
            "niﬁcantly in the ﬁnal generated artifact. This open-endedn ess\n",
            "makes the prompt generic and reusable, but may potentially\n",
            "ask additional questions that could be skipped if more conte xt\n",
            "is given.\n",
            "If speciﬁc requirements are known in advance, it is better to\n",
            "inject them into the prompt rather than hoping the LLM will \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 6: \n",
            "\n",
            "obtain the needed information. Otherwise, the LLM will non-\n",
            "nondeterministically decide whether to prompt the user for the\n",
            "information or make an educated guess as to an appropriate\n",
            "value.\n",
            "For example, the user can state that they would like to\n",
            "deploy an application to Amazon AWS EC2, rather than\n",
            "simply state ”the cloud” and require multiple interactions to\n",
            "narrow down the deployment target. The more precise the\n",
            "initial information, the better the LLM can use the limited\n",
            "questions that a user is likely willing to answer to obtain\n",
            "information to improve its output.\n",
            "When developing prompts for ﬂipped interactions, it is im-\n",
            "portant to consider the level of user knowledge, engagement ,\n",
            "and control. If the goal is to accomplish the goal with as litt le\n",
            "user interaction as possible (minimal control), that shoul d be\n",
            "stated explicitly.Conversely, if the goal is to ensure the u ser\n",
            "is aware of all key decisions and conﬁrms them (maximum \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 6: \n",
            "\n",
            "engagement) that should also be stated explicitly. Likewis e, if\n",
            "the user is expected to have minimal knowledge and should\n",
            "have the questions targeted at their level of expertise, thi s\n",
            "information should be engineered into the prompt.\n",
            "E. The Persona Pattern\n",
            "1) Intent and Context: In many cases, users would like\n",
            "LLM output to always take a certain point of view or per-\n",
            "spective. For example, it may be useful for to conduct a code\n",
            "review as if the LLM was a security expert. The intent of this\n",
            "pattern is to give the LLM a “persona” that helps it select wha t\n",
            "types of output to generate and what details to focus on.\n",
            "2) Motivation: Users may not know what types of outputs\n",
            "or details are important for an LLM to focus on to achieve\n",
            "a given task. They may know, however, the role or type of\n",
            "person that they would normally ask to get help with these\n",
            "things. The Persona pattern enables the users to express what\n",
            "they need help with without knowing the exact details of the\n",
            "outputs they need. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 6: \n",
            "\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Act as persona X\n",
            "Provide outputs that persona X would create\n",
            "The ﬁrst statement conveys the idea that the LLM needs\n",
            "to act as a speciﬁc persona and provide outputs that such a\n",
            "persona would. This persona can be expressed in a number\n",
            "of ways, ranging from a job description, title, ﬁctional cha r-\n",
            "acter, historical ﬁgure, etc. The persona should elicit a se t\n",
            "of attributes associated with a well-known job title, type o f\n",
            "person, etc. 2\n",
            "The secondary idea—provide outputs that persona X would\n",
            "create—offers opportunities for customization. For examp le, a\n",
            "teacher might provide a large variety of different output ty pes,\n",
            "ranging from assignments to reading lists to lectures. If a m ore\n",
            "speciﬁc scope to the type of output is known, the user can\n",
            "provide it in this statement.\n",
            "2Be aware, however, that personas relating to living people o r people \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 6: \n",
            "\n",
            "considered harmful make be disregarded due to underlying LL M privacy and\n",
            "security rules. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 7: \n",
            "\n",
            "4) Example Implementation: A sample implementation for\n",
            "code review is shown below:\n",
            "“From now on, act as a security reviewer. Pay close\n",
            "attention to the security details of any code that\n",
            "we look at. Provide outputs that a security reviewer\n",
            "would regarding the code.”\n",
            "In this example, the LLM is instructed to provide outputs\n",
            "that a ”security reviewer” would. The prompt further sets th e\n",
            "stage that code is going to be evaluated. Finally, the user\n",
            "reﬁnes the persona by scoping the persona further to outputs\n",
            "regarding the code.\n",
            "Personas can also represent inanimate or non-human en-\n",
            "tities, such as a Linux terminal, a database, or an animal’s\n",
            "perspective. When using this pattern to represent these ent ities,\n",
            "it can be useful to also specify how you want the inputs\n",
            "delivered to the entity, such as “assume my input is what the\n",
            "owner is saying to the dog and your output is the sounds the\n",
            "dog is making”. An example prompt for a non-human entity\n",
            "that uses a “pretend to be” wording is shown below: \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 7: \n",
            "\n",
            "“Y ou are going to pretend to be a Linux terminal\n",
            "for a computer that has been compromised by an\n",
            "attacker. When I type in a command, you are going\n",
            "to output the corresponding text that the Linux\n",
            "terminal would produce.”\n",
            "This prompt is designed to simulate a computer that has\n",
            "been compromised by an attacker and is being controlled\n",
            "through a Linux terminal. The prompt speciﬁes that the user\n",
            "will input commands into the terminal, and in response, the\n",
            "simulated terminal will output the corresponding text that\n",
            "would be produced by a real Linux terminal. This prompt\n",
            "is more prescriptive in the persona and asks the LLM to, not\n",
            "only be a Linux terminal, but to further act as a computer that\n",
            "has been compromised by an attacker.\n",
            "The persona causes ChatGPT to generate outputs to com-\n",
            "mands that have ﬁles and contents indicative of a computer th at\n",
            "was hacked. The example illustrates how an LLM can bring\n",
            "its situational awareness to a persona, in this case, creati ng \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 7: \n",
            "\n",
            "evidence of a cyberattack in the outputs it generates. This\n",
            "type of persona can be very effective for combining with the\n",
            "Game Play pattern, where you want the exact details of the\n",
            "output characteristics to be hidden from the user (e.g., don ’t\n",
            "give away what the cyberattack did by describing it explicit ly\n",
            "in the prompt).\n",
            "5) Consequences: An interesting aspect of taking non-\n",
            "human personas is that the LLM may make interesting as-\n",
            "sumptions or “hallucinations” regarding the context. A wid ely\n",
            "circulated example on the Internet asks ChatGPT to act as\n",
            "a Linux terminal and produce the expected output that you\n",
            "would get if the user typed the same text into a terminal.\n",
            "Commands, such as ls -l , will generate a ﬁle listing for an\n",
            "imaginary UNIX ﬁle system, complete with ﬁles that can have\n",
            "cat file1.txt run on them.\n",
            "In other examples, the LLM may prompt the user for more\n",
            "context, such as when ChatGPT is asked to act as a MySQL\n",
            "database and prompts for the structure of a table that the use r \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 7: \n",
            "\n",
            "is pretending to query. ChatGPT can then generate synthetic\n",
            "rows, such as generating imaginary rows for a “people” table\n",
            "with columns for “name” and “job”.\n",
            "F . The Question Reﬁnement Pattern\n",
            "1) Intent and Context: This pattern engages the LLM in\n",
            "the prompt engineering process. The intent of this pattern i s\n",
            "to ensure the conversational LLM always suggests potential ly\n",
            "better or more reﬁned questions the user could ask instead of\n",
            "their original question. Using this pattern, the LLM can aid the\n",
            "user in ﬁnding the right question to ask in order to arrive at a n\n",
            "accurate answer. In addition, the LLM may help the user ﬁnd\n",
            "the information or achieve their goal in fewer interactions with\n",
            "the user than if the user employed trial and error prompting.\n",
            "2) Motivation: If a user is asking a question, it is possible\n",
            "they are not an expert in the domain and may not know the\n",
            "best way to phrase the question or be aware of additional\n",
            "information helpful in phrasing the question. LLMs will oft en \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 7: \n",
            "\n",
            "state limitations on the answer they are providing or reques t\n",
            "additional information to help them produce a more accurate\n",
            "answer. An LLM may also state assumptions it made in\n",
            "providing the answer. The motivation is that this additiona l\n",
            "information or set of assumptions could be used to generate\n",
            "a better prompt. Rather than requiring the user to digest\n",
            "and rephrase their prompt with the additional information,\n",
            "the LLM can directly reﬁne the prompt to incorporate the\n",
            "additional information.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Within scope X, suggest a better version of the question\n",
            "to use instead\n",
            "(Optional) prompt me if I would like to use the better\n",
            "version instead\n",
            "The ﬁrst contextual statement in the prompt is asking the\n",
            "LLM to suggest a better version of a question within a speciﬁc\n",
            "scope. The scope is provided to ensure that not all questions\n",
            "are automatically reworded or that they are reﬁned with a \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 7: \n",
            "\n",
            "given goal. The second contextual statement is meant for\n",
            "automation and allows the user to automatically use the reﬁn ed\n",
            "question without having to copy/paste or manually enter it. The\n",
            "engineering of this prompt can be further reﬁned by combinin g\n",
            "it with the Reﬂection pattern, which allows the LLM to explain\n",
            "why it believes the reﬁned question is an improvement.\n",
            "4) Example Implementation:\n",
            "“From now on, whenever I ask a question about a\n",
            "software artifact’s security, suggest a better version\n",
            "of the question to use that incorporates information\n",
            "speciﬁc to security risks in the language or frame-\n",
            "work that I am using instead and ask me if I would\n",
            "like to use your question instead.”\n",
            "In the context of the example above, the LLM will use\n",
            "the Question Reﬁnement pattern to improve security-related\n",
            "questions by asking for or using speciﬁc details about the \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 8: \n",
            "\n",
            "software artifact and the language or framework used to buil d\n",
            "it. For instance, if a developer of a Python web application w ith\n",
            "FastAPI asks ChatGPT “How do I handle user authentication\n",
            "in my web application?”, the LLM will reﬁne the question\n",
            "by taking into account that the web application is written in\n",
            "Python with FastAPI. The LLM then provides a revised ques-\n",
            "tion that is more speciﬁc to the language and framework, such\n",
            "as “What are the best practices for handling user authentica tion\n",
            "securely in a FastAPI web application to mitigate common\n",
            "security risks, such as cross-site scripting (XSS), cross- site\n",
            "request forgery (CSRF), and session hijacking?”\n",
            "The additional detail in the revised question is likely\n",
            "to not only make the user aware of issues they need to\n",
            "consider, but lead to a better answer from the LLM. For\n",
            "software engineering tasks, this pattern could also incorp orate\n",
            "information regarding potential bugs, modularity, or othe r \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 8: \n",
            "\n",
            "code quality considerations. Another approach would be to\n",
            "automatically reﬁne questions so the generated code cleanl y\n",
            "separates concerns or minimizes use of external libraries, such\n",
            "as:\n",
            "Whenever I ask a question about how to write some\n",
            "code, suggest a better version of my question that\n",
            "asks how to write the code in a way that minimizes\n",
            "my dependencies on external libraries.\n",
            "5) Consequences: The Question Reﬁnement pattern helps\n",
            "bridge the gap between the user’s knowledge and the LLM’s\n",
            "understanding, thereby yielding more efﬁcient and accurat e\n",
            "interactions. One risk of this pattern is its tendency to rap idly\n",
            "narrow the questioning by the user into a speciﬁc area that\n",
            "guides the user down a more limited path of inquiry than\n",
            "necessary. The consequence of this narrowing is that the\n",
            "user may miss important ”bigger picture” information. One\n",
            "solution to this problem is to provide additional scope to th e\n",
            "pattern prompt, such as “do not scope my questions to speciﬁc \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 8: \n",
            "\n",
            "programming languages or frameworks.”\n",
            "Another approach to overcoming arbitrary narrowing or\n",
            "limited targeting of the reﬁned question is to combine the\n",
            "Question Reﬁnement pattern with other patterns. In particular,\n",
            "this pattern can be combined with the Cognitive V eriﬁerpattern\n",
            "so the LLM automatically produces a series of follow-up ques -\n",
            "tions that can produce the reﬁned question. For example, in\n",
            "the following prompt the Question Reﬁnement and Cognitive\n",
            "V eriﬁer patterns are applied to ensure better questions are\n",
            "posed to the LLM:\n",
            "“From now on, whenever I ask a question, ask four\n",
            "additional questions that would help you produce a\n",
            "better version of my original question. Then, use my\n",
            "answers to suggest a better version of my original\n",
            "question.”\n",
            "As with many patterns that allow an LLM to generate\n",
            "new questions using its knowledge, the LLM may introduce\n",
            "unfamiliar terms or concepts to the user into the question.\n",
            "One way to address this issue is to include a statement that \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 8: \n",
            "\n",
            "the LLM should explain any unfamiliar terms it introduces in to\n",
            "the question. A further enhancement of this idea is to combin e\n",
            "the Question Reﬁnement pattern with the Persona pattern so\n",
            "the LLM ﬂags terms and generates deﬁnitions that assume a\n",
            "particular level of knowledge, such as this example:\n",
            "“From now on, whenever I ask a question, ask four\n",
            "additional questions that would help you produce a\n",
            "better version of my original question. Then, use my\n",
            "answers to suggest a better version of my original\n",
            "question. After the follow-up questions, temporarily\n",
            "act as a user with no knowledge of AWS and deﬁne\n",
            "any terms that I need to know to accurately answer\n",
            "the questions.”\n",
            "An LLM can always produce factual inaccuracies, just\n",
            "like a human. A risk of this pattern is that the inaccuracies\n",
            "are introduced into the reﬁned question. This risk may be\n",
            "mitigated, however, by combining the Fact Check List pattern\n",
            "to enable the user to identify possible inaccuracies and the \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 8: \n",
            "\n",
            "Reﬂection pattern to explain the reasoning behind the question\n",
            "reﬁnement.\n",
            "G. The Alternative Approaches Pattern\n",
            "1) Intent and Context: The intent of the pattern is to ensure\n",
            "an LLM always offers alternative ways of accomplishing a tas k\n",
            "so a user does not pursue only the approaches with which they\n",
            "are familiar. The LLM can provide alternative approaches th at\n",
            "always force the user to think about what they are doing and\n",
            "determine if that is the best approach to meet reach their goa l.\n",
            "In addition, solving the task may inform the user or teach the m\n",
            "about alternative concepts for subsequent follow-up.\n",
            "2) Motivation: Humans often suffer from cognitive biases\n",
            "that lead them to choose a particular approach to solve a\n",
            "problem even when it is not the right or “best” approach.\n",
            "Moreover, humans may be unaware of alternative approaches\n",
            "to what they have used in the past. The motivation of the\n",
            "Alternative Approaches pattern is to ensure the user is aware \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 8: \n",
            "\n",
            "of alternative approaches to select a better approach to sol ve\n",
            "a problem by dissolving their cognitive biases.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Within scope X, if there are alternative ways to accom-\n",
            "plish the same thing, list the best alternate approaches\n",
            "(Optional) compare/contrast the pros and cons of each\n",
            "approach\n",
            "(Optional) include the original way that I asked\n",
            "(Optional) prompt me for which approach I would like\n",
            "to use\n",
            "The ﬁrst statement, “within scope X”, scopes the interactio n\n",
            "to a particular goal, topic, or bounds on the questioning. Th e\n",
            "scope is the constraints that the user is placing on the alter -\n",
            "native approaches. The scope could be “for implementation\n",
            "decisions” or “for the deployment of the application”. The\n",
            "scope ensures that any alternatives ﬁt within the boundarie s\n",
            "or constraints that the user must adhere to.\n",
            "The second statement, “if there are alternative ways to \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 8: \n",
            "\n",
            "accomplish the same thing, list the best alternate approach es” \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 9: \n",
            "\n",
            "instructs the LLM to suggest alternatives. As with other\n",
            "patterns, the speciﬁcity of the instructions can be increas ed or\n",
            "include domain-speciﬁc contextual information. For examp le,\n",
            "the statement could be scoped to “if there are alternative wa ys\n",
            "to accomplish the same thing with the software framework tha t\n",
            "I am using” to prevent the LLM from suggesting alternatives\n",
            "that are inherently non-viable because they would require t oo\n",
            "many changes to other parts of the application.\n",
            "Since the user may not be aware of the alternative ap-\n",
            "proaches, they also may not be aware of why one would\n",
            "choose one of the alternatives. The optional statement “com -\n",
            "pare/contrast the pros and cons of each approach” adds de-\n",
            "cision making criteria to the analysis. This statement ensu res\n",
            "the LLM will provide the user with the necessary rationale\n",
            "for alternative approaches. The ﬁnal statement, “prompt me\n",
            "for which approach I would like to use”, helps eliminate the \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 9: \n",
            "\n",
            "user needing to manually copy/paste or enter in an alternati ve\n",
            "approach if one is selected.\n",
            "4) Example Implementation: Example prompt implementa-\n",
            "tion to generate, compare, and allow the user to select one or\n",
            "more alternative approaches:\n",
            "“Whenever I ask you to deploy an application to\n",
            "a speciﬁc cloud service, if there are alternative\n",
            "services to accomplish the same thing with the\n",
            "same cloud service provider, list the best alternative\n",
            "services and then compare/contrast the pros and cons\n",
            "of each approach with respect to cost, availability,\n",
            "and maintenance effort and include the original way\n",
            "that I asked. Then ask me which approach I would\n",
            "like to proceed with.”\n",
            "This implementation of the Alternative Approaches pattern\n",
            "is being speciﬁcally tailored for the context of software\n",
            "engineering and focuses on the deployment of applications\n",
            "to cloud services. The prompt is intended to intercept place s\n",
            "where the developer may have made a cloud service selection \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 9: \n",
            "\n",
            "without full awareness of alternative services that may be\n",
            "priced more competitively or easier to maintain. The prompt\n",
            "directs ChatGPT to list the best alternative services that c an\n",
            "accomplish the same task with the same cloud service provide r\n",
            "(providing constraints on the alternatives), and to compar e and\n",
            "contrast the pros and cons of each approach.\n",
            "5) Consequences: This pattern is effective in its generic\n",
            "form and can be applied to a range of tasks effectively.\n",
            "Reﬁnements could include having a standardized catalog of\n",
            "acceptable alternatives in a speciﬁc domain from which the\n",
            "user must select. The Alternative Approaches pattern can also\n",
            "be used to incentivize users to select one of an approved set\n",
            "of approaches while informing them of the pros/cons of the\n",
            "approved options.\n",
            "H. The Cognitive V eriﬁer Pattern\n",
            "1) Intent and Context: Research literature has documented\n",
            "that LLMs can often reason better if a question is subdivided \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 9: \n",
            "\n",
            "into additional questions that provide answers combined in to\n",
            "the overall answer to the original question [14]. The intent of\n",
            "the pattern is to force the LLM to always subdivide questions\n",
            "into additional questions that can be used to provide a bette r\n",
            "answer to the original question.\n",
            "2) Motivation: The motivation of the Cognitive V eriﬁer\n",
            "pattern is two-fold:\n",
            "• Humans may initially ask questions that are too high-\n",
            "level to provide a concrete answer to without additional\n",
            "follow-up due to unfamiliarity with the domain, laziness\n",
            "in prompt entry, or being unsure about what the correct\n",
            "phrasing of the question should be.\n",
            "• Research has demonstrated that LLMs can often perform\n",
            "better when using a question that is subdivided into\n",
            "individual questions.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "When you are asked a question, follow these rules\n",
            "Generate a number of additional questions that would\n",
            "help more accurately answer the question \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 9: \n",
            "\n",
            "Combine the answers to the individual questions to\n",
            "produce the ﬁnal answer to the overall question\n",
            "The ﬁrst statement is to generate a number of additional\n",
            "questions that would help more accurately answer the origin al\n",
            "question. This step instructs the LLM to consider the contex t\n",
            "of the question and to identify any information that may be\n",
            "missing or unclear. By generating additional questions, th e\n",
            "LLM can help to ensure that the ﬁnal answer is as complete\n",
            "and accurate as possible. This step also encourages critica l\n",
            "thinking by the user and can help to uncover new insights or\n",
            "approaches that may not have been considered initially, whi ch\n",
            "subsequently lead to better follow-on questions.\n",
            "The second statement is to combine the answers to the\n",
            "individual questions to produce the ﬁnal answer to the overa ll\n",
            "question. This step is designed to ensure that all of the info r-\n",
            "mation gathered from the individual questions is incorpora ted\n",
            "into the ﬁnal answer. By combining the answers, the LLM \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 9: \n",
            "\n",
            "can provide a more comprehensive and accurate response to\n",
            "the original question. This step also helps to ensure that al l\n",
            "relevant information is taken into account and that the ﬁnal\n",
            "answer is not based on any single answer.\n",
            "4) Example Implementation:\n",
            "“When I ask you a question, generate three addi-\n",
            "tional questions that would help you give a more\n",
            "accurate answer. When I have answered the three\n",
            "questions, combine the answers to produce the ﬁnal\n",
            "answers to my original question.”\n",
            "This speciﬁc instance of the prompt pattern adds a reﬁne-\n",
            "ment to the original pattern by specifying a set number of\n",
            "additional questions that the LLM should generate in respon se\n",
            "to a question. In this case, the prompt speciﬁes that ChatGPT\n",
            "should generate three additional questions that would help to\n",
            "give a more accurate answer to the original question. The\n",
            "speciﬁc number can be based on the user’s experience and\n",
            "willingness to provide follow-up information. A reﬁnement \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 9: \n",
            "\n",
            "to the prompt can be to provide a context for the amount \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 10: \n",
            "\n",
            "of knowledge that the LLM can assume the user has in the\n",
            "domain to guide the creation of the additional questions:\n",
            "“When I ask you a question, generate three addi-\n",
            "tional questions that would help you give a more\n",
            "accurate answer. Assume that I know little about\n",
            "the topic that we are discussing and please deﬁne\n",
            "any terms that are not general knowledge. When\n",
            "I have answered the three questions, combine the\n",
            "answers to produce the ﬁnal answers to my original\n",
            "question.”\n",
            "The reﬁnement also speciﬁes that the user may not have\n",
            "a strong understanding of the topic being discussed, which\n",
            "means that the LLM should deﬁne any terms that are not\n",
            "general knowledge. This helps to ensure that the follow-up\n",
            "questions are not only relevant and focused, but also access ible\n",
            "to the user, who may not be familiar with technical or domain-\n",
            "speciﬁc terms. By providing clear and concise deﬁnitions, t he\n",
            "LLM can help to ensure that the follow-up questions are easy \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 10: \n",
            "\n",
            "to understand and that the ﬁnal answer is accessible to users\n",
            "with varying levels of knowledge and expertise.\n",
            "5) Consequences: This pattern can dictate the exact number\n",
            "of questions to generate or leave this decision to the LLM.\n",
            "There are pros and cons to dictating the exact number. A pro\n",
            "is that specifying an exact number of questions can tightly\n",
            "scope the amount of additional information the user is force d\n",
            "to provide so it is within a range they are willing and able to\n",
            "contribute.\n",
            "A con, however, is that given N questions there may be\n",
            "an invaluable N + 1 question that will always be scoped out.\n",
            "Alternatively, the LLM can be provided a range or allowed\n",
            "to ask additional questions. Of course, by omitting a limit o n\n",
            "the number of questions the LLM may generate numerous\n",
            "additional questions that overwhelm the user.\n",
            "I. The Fact Check List Pattern\n",
            "1) Intent and Context: The intent of this pattern is to ensure\n",
            "that the LLM outputs a list of facts that are present in the \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 10: \n",
            "\n",
            "output and form an important part of the statements in the\n",
            "output. This list of facts helps inform the user of the facts\n",
            "(or assumptions) the output is based on. The user can then\n",
            "perform appropriate due diligence on these facts/assumpti ons\n",
            "to validate the veracity of the output.\n",
            "2) Motivation: A current weakness of LLMs (including\n",
            "ChatGPT) is they often rapidly (and even enthusiastically! )\n",
            "generate convincing text that is factually incorrect. Thes e\n",
            "errors can take a wide range of forms, including fake statist ics\n",
            "to invalid version numbers for software library dependenci es.\n",
            "Due to the convincing nature of this generated text, however ,\n",
            "users may not perform appropriate due diligence to determin e\n",
            "its accuracy.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Generate a set of facts that are contained in the output\n",
            "The set of facts should be inserted in a speciﬁc point\n",
            "in the output\n",
            "The set of facts should be the fundamental facts that \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 10: \n",
            "\n",
            "could undermine the veracity of the output if any of\n",
            "them are incorrect\n",
            "One point of variation in this pattern is where the facts are\n",
            "output. Given that the facts may be terms that the user is not\n",
            "familiar with, it is preferable if the list of facts comes aft er\n",
            "the output. This after-output presentation ordering allow s the\n",
            "user to read and understand the statements before seeing wha t\n",
            "statements should be checked. The user may also determine\n",
            "additional facts prior to realizing the fact list at the end s hould\n",
            "be checked.\n",
            "4) Example Implementation: A sample wording of the Fact\n",
            "Check List pattern is shown below:\n",
            "“From now on, when you generate an answer, create\n",
            "a set of facts that the answer depends on that should\n",
            "be fact-checked and list this set of facts at the\n",
            "end of your output. Only include facts related to\n",
            "cybersecurity.”\n",
            "The user may have expertise in some topics related to the\n",
            "question but not others. The fact check list can be tailored t o \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 10: \n",
            "\n",
            "topics that the user is not as experienced in or where there\n",
            "is the most risk. For example, in the prompt above, the user\n",
            "is scoping the fact check list to security topics, since thes e\n",
            "are likely very important from a risk perspective and may not\n",
            "be well-understood by the developer. Targeting the facts al so\n",
            "reduces the cognitive burden on the user by potentially list ing\n",
            "fewer items for investigation.\n",
            "5) Consequences: The Fact Check List pattern should be\n",
            "employed whenever users are not experts in the domain for\n",
            "which they are generating output. For example, a software\n",
            "developer reviewing code could beneﬁt from the pattern\n",
            "suggesting security considerations. In contrast, an exper t on\n",
            "software architecture is likely to identify errors in state ments\n",
            "about the software structure and need not see a fact check lis t\n",
            "for these outputs.\n",
            "Errors are potential in all LLM outputs, so Fact Check List\n",
            "is an effective pattern to combine with other patterns, such \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 10: \n",
            "\n",
            "as by combining it with the Question Reﬁnement pattern. A\n",
            "key aspect of this pattern is that users can inherently check it\n",
            "against the output. In particular, users can directly compa re the\n",
            "fact check list to the output to verify the facts listed in the fact\n",
            "check list actually appear in the output. Users can also iden tify\n",
            "any omissions from the list. Although the fact check list may\n",
            "also have errors, users often have sufﬁcient knowledge and\n",
            "context to determine its completeness and accuracy relativ e to\n",
            "the output.\n",
            "One caveat of the Fact Check List pattern is that it only\n",
            "applies when the output type is amenable to fact-checking. F or\n",
            "example, the pattern works when asking ChatGPT to generate\n",
            "a Python “requirements.txt” ﬁle since it will list the versi ons\n",
            "of libraries as facts that should be checked, which is handy a s \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 11: \n",
            "\n",
            "the versions commonly have errors. However, ChatGPT will\n",
            "refuse to generate a fact check list for a code sample and\n",
            "indicate that this is something it cannot check, even though\n",
            "the code may have errors.\n",
            "J. The T emplate Pattern\n",
            "1) Intent and Context: The intent of the pattern is to\n",
            "ensure an LLM’s output follows a precise template in terms of\n",
            "structure. For example, the user might need to generate a URL\n",
            "that inserts generated information into speciﬁc positions within\n",
            "the URL path. This pattern allows the user to instruct the LLM\n",
            "to produce its output in a format it would not ordinarily use\n",
            "for the speciﬁed type of content being generated.\n",
            "2) Motivation: In some cases, output must be produced in\n",
            "a precise format that is application or use-case speciﬁc and\n",
            "not known to the LLM. Since the LLM is not aware of the\n",
            "template structure, it must be instructed on what the format\n",
            "is and where the different parts of its output should go. This \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 11: \n",
            "\n",
            "could take the form of a sample data structure that is being\n",
            "generated, a series of form letters being ﬁlled in, etc.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "I am going to provide a template for your output\n",
            "X is my placeholder for content\n",
            "Try to ﬁt the output into one or more of the placehold-\n",
            "ers that I list\n",
            "Please preserve the formatting and overall template that\n",
            "I provide\n",
            "This is the template: P A TTERN with PLACEHOLD-\n",
            "ERS\n",
            "The ﬁrst statement directs the LLM to follow a speciﬁc\n",
            "template for its output. The template will be used to try and\n",
            "coerce the LLMs responses into a structure that is consisten t\n",
            "with the user’s formatting needs. This pattern is needed whe n\n",
            "the target format is not known to the LLM. If the LLM already\n",
            "has knowledge of the format, such as a speciﬁc ﬁle type, then\n",
            "the template pattern can be skipped and the user can simply\n",
            "specify the known format. However, there may be cases, such \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 11: \n",
            "\n",
            "as generating Javascript Object Notation (JSON), where the re\n",
            "is a large amount of variation in how the data could be\n",
            "represented within that format and the template can be used t o\n",
            "ensure that the representation within the target format mee ts\n",
            "the user’s additional constraints.\n",
            "The second statement makes the LLM aware that the\n",
            "template will contain a set of placeholders. Users will expl ain\n",
            "how the output should be inserted into the template through t he\n",
            "placeholders. The placeholders allow the user to semantica lly\n",
            "target where information should be inserted. Placeholders\n",
            "can use formats, like NAME, that allow the LLM to infer\n",
            "the semantic meaning of to determine where output should\n",
            "be inserted (e.g., insert the person’s name in the NAME\n",
            "placeholder). Moreover, by using placeholders, the user ca n\n",
            "indicate what is not needed in the output – if a placeholder\n",
            "doesn’t exist for a component of the generated output, then\n",
            "that component can be omitted. Ideally, placeholders shoul d \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 11: \n",
            "\n",
            "use a format that is commonly employed in text that the LLM\n",
            "was trained on, such as all caps, enclosure in brackets, etc.\n",
            "The third statement attempts to constrain the LLM so that it\n",
            "doesn’t arbitrarily rewrite the template or attempt to modi fy it\n",
            "so that all of the output components can be inserted. It shoul d\n",
            "be noted that this statement may not preclude additional tex t\n",
            "from being generated before or after. In practice, LLMs will\n",
            "typically follow the template, but it is harder to eliminate any\n",
            "additional text being generated beyond the template withou t\n",
            "experimentation with prompt wording.\n",
            "4) Example Implementation: A sample template for gener-\n",
            "ating URLs where the output is put into speciﬁc places in the\n",
            "template is shown below:\n",
            "“I am going to provide a template for your out-\n",
            "put. Everything in all caps is a placeholder. Any\n",
            "time that you generate text, try to ﬁt it into one\n",
            "of the placeholders that I list. Please preserve the\n",
            "formatting and overall template that I provide at \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 11: \n",
            "\n",
            "https://myapi.com/NAME/proﬁle/JOB”\n",
            "A sample interaction after the prompt was provided, is\n",
            "shown:\n",
            "User: “Generate a name and job title for a person”\n",
            "ChatGPT: “https://myapi.com/Emily\n",
            "Parker/proﬁle/\n",
            "Software Engineer”\n",
            "5) Consequences: One consequence of applying the T em-\n",
            "plate pattern is that it ﬁlters the LLM’s output, which may\n",
            "eliminate other outputs the LLM would have provided that\n",
            "might be useful to the user. In many cases, the LLM can\n",
            "provide helpful descriptions of code, decision making, or o ther\n",
            "details that this pattern will effectively eliminate from t he\n",
            "output. Users should therefore weight the pros/cons of ﬁlte ring\n",
            "out this additional information.\n",
            "In addition, ﬁltering can make it hard to combine this patter n\n",
            "with other patterns from the Output Customization category.\n",
            "The T emplatepattern effectively constrains the output format,\n",
            "so it may not be compatible with generation of certain other\n",
            "types of output. For example, in the template provided above \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 11: \n",
            "\n",
            "for a URL, it would not be easy (or likely possible) to combine\n",
            "with the Recipe pattern, which needs to output a list of steps.\n",
            "K. The Inﬁnite Generation Pattern\n",
            "1) Intent and Context: The intent of this pattern is to\n",
            "automatically generate a series of outputs (which may appea r\n",
            "inﬁnite) without having to reenter the generator prompt eac h\n",
            "time. The goal is to limit how much text the user must type to\n",
            "produce the next output, based on the assumption that the use r\n",
            "does not want to continually reintroduce the prompt. In some\n",
            "variations, the intent is to allow the user to keep an initial\n",
            "prompt template, but add additional variation to it through\n",
            "additional inputs prior to each generated output.\n",
            "2) Motivation: Many tasks require repetitive application of\n",
            "the same prompt to multiple concepts. For example, generati ng\n",
            "code for create, read, update, and delete (CRUD) operations\n",
            "for a speciﬁc type of entity may require applying the same \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 12: \n",
            "\n",
            "prompt to multiple types of entities. If the user is forced to\n",
            "retype the prompt over and over, they may make mistakes. The\n",
            "Inﬁnite Generation pattern allows the user to repetitively apply\n",
            "a prompt, either with or without further input, to automate\n",
            "the generation of multiple outputs using a predeﬁned set of\n",
            "constraints.\n",
            "3) Structure and Key Ideas:\n",
            "Contextual Statements\n",
            "I would like you to generate output forever, X output(s)\n",
            "at a time.\n",
            "(Optional) here is how to use the input I provide\n",
            "between outputs.\n",
            "(Optional) stop when I ask you to.\n",
            "The ﬁrst statement speciﬁes that the user wants the LLM\n",
            "to generate output indeﬁnitely, which effectively conveys the\n",
            "information that the same prompt is going to be reused over\n",
            "and over. By specifying the number of outputs that should be\n",
            "generated at a time (i.e. “X outputs at a time”), the user can\n",
            "rate limit the generation, which can be particularly import ant if\n",
            "there is a risk that the output will exceed the length limitat ions \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 12: \n",
            "\n",
            "of the LLM for a single output.\n",
            "The second statement provides optional instructions for ho w\n",
            "to use the input provided by the user between outputs. By\n",
            "specifying how additional user inputs between prompts can\n",
            "be provided and leveraged, the user can create a prompting\n",
            "strategy that leverages user feedback in the context of the\n",
            "original prompt. The original prompt is still in the context of\n",
            "the generation, but each user input between generation step s\n",
            "is incorporated into the original prompt to reﬁne the output\n",
            "using prescribed rules.\n",
            "The third statement provides an optional way for the user\n",
            "to stop the output generation process. This step is not alway s\n",
            "needed, but can be useful in situations where there may be\n",
            "the potential for ambiguity regarding whether or not the use r-\n",
            "provided input between inputs is meant as a reﬁnement for\n",
            "the next generation or a command to stop. For example, an\n",
            "explicit stop phrase could be created if the user was generat ing \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 12: \n",
            "\n",
            "data related to road signs, where the user might want to enter\n",
            "a reﬁnement of the generation like “stop” to indicate that a\n",
            "stop sign should be added to the output.\n",
            "4) Example Implementation: The following is a sample\n",
            "inﬁnite generation prompt for producing a series of URLs:\n",
            "“From now on, I want you to generate a name\n",
            "and job until I say stop. I am going to provide a\n",
            "template for your output. Everything in all caps is a\n",
            "placeholder. Any time that you generate text, try to\n",
            "ﬁt it into one of the placeholders that I list. Please\n",
            "preserve the formatting and overall template that I\n",
            "provide: https://myapi.com/NAME/proﬁle/JOB”\n",
            "This prompt is combining the functionality of both the\n",
            "Inﬁnite Generation pattern and the T emplatepattern. The user\n",
            "is requesting the LLM continuously generate a name and job\n",
            "title until explicitly told to “stop”. The generated output s are\n",
            "then formatted into the template provided, which includes\n",
            "placeholders for the name and job title. By using the Inﬁnite \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 12: \n",
            "\n",
            "Generation pattern, the user receives multiple outputs without\n",
            "having to continually re-enter the template. Likewise, the\n",
            "T emplatepattern is applied to provide a consistent format for\n",
            "the outputs.\n",
            "5) Consequences: In conversational LLMs, the input to\n",
            "the model at each time step is the previous output and the\n",
            "new user input. Although the details of what is preserved\n",
            "and reintroduced in the next output cycle are model and\n",
            "implementation dependent, they are often limited in scope. The\n",
            "model is therefore constantly being fed the previous output s\n",
            "and the prompt, which can result in the model losing track of\n",
            "the original prompt instructions over time if they exceed th e\n",
            "scope of what it is being provided as input.\n",
            "As additional outputs are generated, the context surroundi ng\n",
            "the prompt may fade, leading to the model deviating from\n",
            "the intended behavior. It is important to monitor the output s\n",
            "produced by the model to (1) ensure it still adheres to \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 12: \n",
            "\n",
            "the desired behavior and (2) provide corrective feedback if\n",
            "necessary. Another issue to consider is that the LLM may\n",
            "generate repetitive outputs, which may not be desired since\n",
            "users ﬁnd this repetition tedious and error-prone to proces s.\n",
            "L. The Visualization Generator Pattern\n",
            "1) Intent and Context: The intent of this pattern is to use\n",
            "text generation to create visualizations. Many concepts ar e\n",
            "easier to grasp in diagram or image format. The purpose of\n",
            "this pattern is to create a pathway for the tool to produce\n",
            "imagery that is associated with other outputs. This pattern\n",
            "allows the creation of visualizations by creating inputs fo r\n",
            "other well-known visualization tools that use text as their\n",
            "input, such as Graphviz Dot [15] or DALL-E [13]. This\n",
            "pattern can provide a more comprehensive and effective way\n",
            "of communicating information by combining the strengths of\n",
            "both the text generation and visualization tools.\n",
            "2) Motivation: LLMs generally produce text and cannot \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 12: \n",
            "\n",
            "produce imagery. For example, an LLM cannot draw a diagram\n",
            "to describe a graph. The Visualization Generator pattern over-\n",
            "comes this limitation by generating textual inputs in the co rrect\n",
            "format to plug into another tool that generates the correct\n",
            "diagram. The motivation behind this pattern is to enhance th e\n",
            "output of the LLM and make it more visually appealing and\n",
            "easier to understand for users. By using text inputs to gener ate\n",
            "visualizations, users can quickly understand complex conc epts\n",
            "and relationships that may be hard to grasp through text alon e.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Generate an X that I can provide to tool Y to visualize\n",
            "it\n",
            "The goal of the contextual statements is to indicate to the\n",
            "LLM that the output it is going to produce, “X”, is going to\n",
            "be imagery. Since LLMs can’t generate images, the ”that I\n",
            "can provide to tool Y to visualize it” clariﬁes that the LLM \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 12: \n",
            "\n",
            "is not expected to generate an image, but is instead expected \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 13: \n",
            "\n",
            "to produce a description of imagery consumable by tool Y for\n",
            "production of the image.\n",
            "Many tools may support multiple types of visualizations or\n",
            "formats, and thus the target tool itself may not be sufﬁcient\n",
            "information to accurately produce what the user wants. The\n",
            "user may need to state the precise types of visualizations (e .g.,\n",
            "bar chart, directed graph, UML class diagram) that should be\n",
            "produced. For example, Graphviz Dot can create diagrams for\n",
            "both UML class diagrams and directed graphs. Further, as wil l\n",
            "be discussed in the following example, it can be advantageou s\n",
            "to specify a list of possible tools and formats and let the LLM\n",
            "select the appropriate target for visualization.\n",
            "4) Example Implementation:\n",
            "“Whenever I ask you to visualize something, please\n",
            "create either a Graphviz Dot ﬁle or DALL-E prompt\n",
            "that I can use to create the visualization. Choose\n",
            "the appropriate tools based on what needs to be\n",
            "visualized.”\n",
            "This example of the pattern adds a qualiﬁcation that the \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 13: \n",
            "\n",
            "output type for the visualization can be either for Graphviz\n",
            "or DALL-E. The interesting aspect of this approach is that\n",
            "it allows the LLM to use its semantic understanding of the\n",
            "output format to automatically select the target tooling ba sed\n",
            "on what will be displayed. In this case, Graphviz would be for\n",
            "visualizing graphs with a need for an exactly deﬁned structu re.\n",
            "DALL-E would be effective at visualizing realistic or artis tic\n",
            "imagery that does not have an exactly deﬁned structure. The\n",
            "LLM can select the tool based on the needs of the visualizatio n\n",
            "and capabilities of each tool.\n",
            "5) Consequences: The pattern creates a target pipeline\n",
            "for the output to render a visualization. The pipeline may\n",
            "include AI generators, such as DALL-E, that can produce\n",
            "rich visualizations. The pattern allows the user to expand t he\n",
            "expressive capabilities of the output into the visual domai n.\n",
            "M. The Game Play Pattern\n",
            "1) Intent and Context: The intent of this pattern is to create \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 13: \n",
            "\n",
            "a game around a given topic. The pattern can be combined\n",
            "with the Visualization Generator to add imagery to the game.\n",
            "The game is centered around a speciﬁc topic and the LLM\n",
            "will guide the game play. The pattern is particularly effect ive\n",
            "when the rules of the game are relatively limited in scope, bu t\n",
            "the content for the game is expected to be wide in scope. The\n",
            "user can specify a limited set of rules and then the LLM can\n",
            "automate generation of bodies of content for game play.\n",
            "2) Motivation: Y ou would like the LLM to generate scenar-\n",
            "ios or questions revolving around a speciﬁc topic and requir e\n",
            "users to apply problem solving or other skills to accomplish\n",
            "a task related to the scenario. Generating all the content fo r\n",
            "the game manually would be too time consuming, however, so\n",
            "you would like the LLM to apply its knowledge of the topic\n",
            "to guide the generation of content.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 13: \n",
            "\n",
            "Create a game for me around X\n",
            "One or more fundamental rules of the game\n",
            "The ﬁrst statement, instructs the LLM to create a game and\n",
            "provides the important scoping of the game to a topic area. .\n",
            "One of the important capabilities of the pattern is that it al lows\n",
            "the user to create games by describing the rules of the game,\n",
            "without having to determine the content of the game. The more\n",
            "speciﬁc the topic, typically the more novel and interesting the\n",
            "game play.\n",
            "The second statement introduces the rules of the game to the\n",
            "LLM. It is important that the rules ﬁt within the capabilitie s\n",
            "of the LLM. Textual games that rely on input and output text\n",
            "sequences work best. One of the key attributes of the pattern\n",
            "is that the input text can be rich and expressive, which can\n",
            "lead to interesting interfaces for the game. For example, th e\n",
            "user might express actions in the game as scripts dictating\n",
            "a sequence of complex actions, such as “get a listing of all \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 13: \n",
            "\n",
            "network activity and check it for anomalies”, which go beyon d\n",
            "the scope of multiple choice or short answer inputs. Each rul e\n",
            "should be provided as a separate statement regarding some\n",
            "aspect of the game.\n",
            "4) Example Implementation: A sample cybersecurity game\n",
            "prompt is shown below:\n",
            "“We are going to play a cybersecurity game. Y ou\n",
            "are going to pretend to be a Linux terminal for a\n",
            "computer that has been compromised by an attacker.\n",
            "When I type in a command, you are going to output\n",
            "the corresponding text that the Linux terminal would\n",
            "produce. I am going to use commands to try and\n",
            "ﬁgure out how the system was compromised. The\n",
            "attack should have done one or more of the following\n",
            "things: (1) launched new processes, (2) changed\n",
            "ﬁles, (3) opened new ports to receive communi-\n",
            "cation, (4) created new outbound connections, (5)\n",
            "changed passwords, (6) created new user accounts,\n",
            "or (7) read and stolen information. To start the game,\n",
            "print a scenario of what happened that led to my \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 13: \n",
            "\n",
            "investigation and make the description have clues\n",
            "that I can use to get started.”\n",
            "This cybersecurity game prompt combines a number of pat-\n",
            "terns, including Game Play and Persona. The Linux terminal\n",
            "persona that is chosen for the game has been discussed in many\n",
            "Internet posts [16]. This game further customizes the discu ssed\n",
            "Linux persona to act as a Linux terminal of a computer\n",
            "compromised by a cyberattack. ChatGPT responds to Linux\n",
            "commands with appropriate terminal outputs and synthesize s\n",
            "a fake ﬁle system that has clues to a cyberattack.\n",
            "Sample output from this game with ChatGPT after typing\n",
            "in “ls -alt”, the Linux command to generate a list of ﬁles in\n",
            "the current directory is shown below (permissions have been\n",
            "removed for formatting reasons):\n",
            "total 56\n",
            "5 user user 4096 Feb 16 14:31 .\n",
            "1 user user 18881 Feb 16 14:31 .bash_history \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 14: \n",
            "\n",
            "43 user user 4096 Feb 16 14:30 ..\n",
            "1 user user 1178 Aug 15 2022 .bashrc\n",
            "1 user user 220 Aug 15 2022 .bash_logout\n",
            "3 user user 4096 Feb 16 14:25 .gnupg\n",
            "1 user user 4041 Feb 15 17:52 README.md\n",
            "2 user user 4096 Feb 1 11:35 project\n",
            "When the user then typed the command “cat .bash\n",
            "history”,\n",
            "to display the contents of the log ﬁle showing the commands\n",
            "run by the user, ChatGPT responded with:\n",
            "cd /var/www/html\n",
            "sudo rm -rf *\n",
            "sudo wget https://example.com/backdoor.php\n",
            "sudo chmod 777 backdoor.php\n",
            "exit\n",
            "ls -alt\n",
            "ps -ef\n",
            "netstat -tulnp\n",
            "In the output above, ChatGPT generated a fake log ﬁle with\n",
            "realistic commands for deleting the data being served by the\n",
            "web server in /var/www/html and replacing the content\n",
            "with a backdoor into the system.\n",
            "5) Consequences: This pattern can be combined effectively\n",
            "with the Persona, Inﬁnite Generation , and Visualization Gen-\n",
            "erator patterns. For example, the cybersecurity game uses the\n",
            "Persona pattern so the LLM can masquerade as a Linux termi- \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 14: \n",
            "\n",
            "nal. For a network security game, the Visualization Generator\n",
            "could be employed to add the ability to visualize the network\n",
            "topology and trafﬁc ﬂows.\n",
            "N. The Reﬂection Pattern\n",
            "1) Intent and Context: The goal of this pattern is to ask\n",
            "the model to automatically explain the rationale behind giv en\n",
            "answers to the user. The pattern allows users to better asses s\n",
            "the output’s validity, as well as inform users how an LLM\n",
            "arrived at a particular answer. Reﬂection can clarify any po ints\n",
            "of confusion, uncover underlying assumptions, and reveal g aps\n",
            "in knowledge or understanding.\n",
            "2) Motivation: LLMs can and do make mistakes. More-\n",
            "over, users may not understand why an LLM is producing\n",
            "a particular output and how to adapt their prompt to solve\n",
            "a problem with the output. By asking LLM to automatically\n",
            "explain the rationale behind its answers, users can gain a be tter\n",
            "understanding of how the model is processing the input, what\n",
            "assumptions it is making, and what data it is drawing on. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 14: \n",
            "\n",
            "LLMs may sometime provide incomplete, incorrect, or\n",
            "ambiguous answers. Reﬂection is an aid to help address these\n",
            "shortcomings and ensure the information provided by LLM\n",
            "is as accurate. A further beneﬁt of the pattern is that it can\n",
            "help users debug their prompts and determine why they are\n",
            "not getting results that meet expectations. This pattern is\n",
            "particularly effective for the exploration of topics that c an\n",
            "be confused with other topics or that may have nuanced\n",
            "interpretations and where knowing the precise interpretat ion\n",
            "that the LLM used is important.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Whenever you generate an answer\n",
            "Explain the reasoning and assumptions behind your\n",
            "answer\n",
            "(Optional) ...so that I can improve my question\n",
            "The ﬁrst statement is requesting that, after generating an a n-\n",
            "swer, the LLM should explain the reasoning and assumptions\n",
            "behind the answer. This statement helps the user understand \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 14: \n",
            "\n",
            "how the LLM arrived at the answer and can help build trust in\n",
            "the model’s responses. The prompt includes the statement th at\n",
            "the purpose of the explanation is for the user to reﬁne their\n",
            "question. This additional statement gives the LLM the conte xt\n",
            "it needs to better tailor its explanations to the speciﬁc pur pose\n",
            "of aising the user in producing follow-on questions.\n",
            "4) Example Implementation: This example tailors the\n",
            "prompt speciﬁcally to the domain of providing answers relat ed\n",
            "to code:\n",
            "”When you provide an answer, please explain the\n",
            "reasoning and assumptions behind your selection\n",
            "of software frameworks. If possible, use speciﬁc\n",
            "examples or evidence with associated code samples\n",
            "to support your answer of why the framework is\n",
            "the best selection for the task. Moreover, please\n",
            "address any potential ambiguities or limitations in\n",
            "your answer, in order to provide a more complete\n",
            "and accurate response.”\n",
            "The pattern is further customized to instruct the LLM that \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 14: \n",
            "\n",
            "it should justify its selection of software frameworks, but not\n",
            "necessarily other aspects of the answer. In addition, the us er\n",
            "dictates that code samples should be used to help explain the\n",
            "motivation for selecting the speciﬁc software framework.\n",
            "5) Consequences: One consequence of the Reﬂection pat-\n",
            "tern is that it may not be effective for users who do not\n",
            "understand the topic area of the discussion. For example, a\n",
            "highly technical question by a non-technical user may resul t\n",
            "in a complex rationale for the answer that the user cannot\n",
            "fathom. As with other prompt patterns, there is a risk the\n",
            "output may include errors or inaccurate assumptions includ ed\n",
            "in the explanation of the rationale that the user may not be\n",
            "able to spot. This pattern can be combined with the Fact Check\n",
            "List to help address this issue.\n",
            "O. The Refusal Breaker Pattern\n",
            "1) Intent and Context: The goal of this pattern is to ask an\n",
            "LLM to automatically help users rephrase a question when it \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 14: \n",
            "\n",
            "refuses to give an answer. This pattern has the potential for\n",
            "misuse, however, e.g., to generate phishing emails or perform\n",
            "other actions that violate LLM policy ﬁlters. Caution shoul d\n",
            "therefore be exercised when applying this pattern to ensure\n",
            "it is used ethically and responsibly. This pattern has been\n",
            "used successfully in some LLMs to overcome the underlying\n",
            "prompts used to program the LLM and prevent harmful output\n",
            "generation. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 15: \n",
            "\n",
            "2) Motivation: LLMs may sometimes refuse to answer\n",
            "a question, either because they do not have the required\n",
            "knowledge or because the question is phrased in a way that\n",
            "they do not understand. This outcome may be frustrating\n",
            "for users who are looking for answers. In some situations,\n",
            "therefore, the Refusal Breaker pattern can help users ﬁnd a\n",
            "way to either rephrase their question or ask a different ques tion\n",
            "the LLM is better equipped to answer.\n",
            "For example, you could ask for clariﬁcation on why the\n",
            "question was refused, as there may be a speciﬁc reason why\n",
            "LLM could not provide an answer. Another approach is to\n",
            "ask a different question that may be within its knowledge cut -\n",
            "off or expertise. However, all these approaches require use r\n",
            "intervention and knowledge of how to bypass the refusal.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Whenever you can’t answer a question\n",
            "Explain why you can’t answer the question \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 15: \n",
            "\n",
            "Provide one or more alternative wordings of the ques-\n",
            "tion that you could answer\n",
            "The ﬁrst statement sets the stage that this set of instructio ns\n",
            "should only be applied when a question can’t be answered.\n",
            "The user does not want to trigger these instructions under\n",
            "normal circumstances. The second statement instructs the\n",
            "LLM to provide an explanation of why the question can’t be\n",
            "answered. The explanation is likely to include assumptions ,\n",
            "constraints, or misunderstandings that can be leveraged by the\n",
            "user to strategize about how to reword the question. Althoug h\n",
            "just the explanation of why the question can’t be answered\n",
            "could help a user overcome the refusal, the pattern adds an\n",
            "additional statement for the LLM to suggest rewordings that\n",
            "would be acceptable. The pattern combines both reasoning\n",
            "and suggested rewordings to improve the chances that the use r\n",
            "will ﬁnd a path around whatever roadblocks are preventing th e\n",
            "question form being answered. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 15: \n",
            "\n",
            "4) Example Implementation: The Refusal Breaker pattern\n",
            "can be be implemented and applied with the following phras-\n",
            "ing:\n",
            "“Whenever you can’t answer a question, explain why\n",
            "and provide one or more alternate wordings of the\n",
            "question that you can’t answer so that I can improve\n",
            "my questions.”\n",
            "A sample discourse after using the pattern is shown below:\n",
            "User: What is the meaning of life?\n",
            "ChatGPT: As an AI language model, I do not\n",
            "have personal beliefs or opinions. The meaning of\n",
            "life is a complex philosophical question that has\n",
            "been pondered by humans for centuries and can\n",
            "vary greatly from person to person. It may be more\n",
            "productive to rephrase the question in a way that can\n",
            "be answered by information and knowledge, such\n",
            "as “What are some philosophical perspectives on\n",
            "the meaning of life?” or “What are some common\n",
            "beliefs about the purpose of life?”\n",
            "5) Consequences: This pattern provides a potential path\n",
            "for misuse, so organizations, parents, or other stakeholde rs \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 15: \n",
            "\n",
            "may need to restrict the usage of the LLM. The ﬁrst step in\n",
            "going around guardrails on usage is to understand where the\n",
            "guardrails are. In future work, a complement of this pattern\n",
            "may be developed to hide the underlying prompt information\n",
            "and rationale from users to prevent discovery.\n",
            "Although the rationale and alternate rewordings are gener-\n",
            "ated, there is no guarantee that users will be able to overcom e\n",
            "the refusal. The alternate questions that are generated may not\n",
            "be of interest to the user or helpful in answering the origina l\n",
            "question. The pattern mainly provides an aid in determining\n",
            "what the LLM can answer, but not a guarantee that it will\n",
            "answer a semantically equivalent variation of the original\n",
            "question.\n",
            "P . The Context Manager Pattern\n",
            "1) Intent and Context: The intent of this pattern is to enable\n",
            "users to specify or remove context for a conversation with\n",
            "an LLM. The goal is to focus the conversation on speciﬁc\n",
            "topics or exclude unrelated topics from consideration. Thi s \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 15: \n",
            "\n",
            "pattern gives users greater control over what statements th e\n",
            "LLM considers or ignores when generating output.\n",
            "2) Motivation: LLMs often struggle to interpret the in-\n",
            "tended context of the current question or generate irreleva nt\n",
            "responses based on prior inputs or irrelevant attention on\n",
            "the wrong statements. By focusing on explicit contextual\n",
            "statements or removing irrelevant statements, users can he lp\n",
            "the LLM better understand the question and generate more\n",
            "accurate responses. Users may introduce unrelated topics o r\n",
            "reference information from earlier in the dialogue, which\n",
            "may can disrupt the ﬂow of the conversation. The Context\n",
            "Manager pattern aims to emphasize or remove speciﬁc aspects\n",
            "of the context to maintain relevance and coherence in the\n",
            "conversation.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "Within scope X\n",
            "Please consider Y\n",
            "Please ignore Z\n",
            "(Optional) start over\n",
            "Statements about what to consider or ignore should list key \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 15: \n",
            "\n",
            "concepts, facts, instructions, etc. that should be include d or\n",
            "removed from the context. The more explicit the statements\n",
            "are, the more likely the LLM will take appropriate action. Fo r\n",
            "example, if the user asks to ignore subjects related to a topi c,\n",
            "yet some of the those statements were discussed far back in th e\n",
            "conversation, the LLM may not properly disregard the releva nt\n",
            "information. The more explicit the list is, therefore, the b etter\n",
            "the inclusion/exclusion behavior will be. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 16: \n",
            "\n",
            "4) Example Implementation: To specify context consider\n",
            "using the following prompt:\n",
            "“When analyzing the following pieces of code, only\n",
            "consider security aspects.”\n",
            "Likewise, to remove context consider using the following\n",
            "prompt:\n",
            "“When analyzing the following pieces of code, do\n",
            "not consider formatting or naming conventions.”\n",
            "Clarity and speciﬁcity are important when providing or\n",
            "removing context to/from an LLM so it can better understand\n",
            "the intended scope of the conversation and generate more\n",
            "relevant responses. In many situations, the user may want to\n",
            "completely start over and can employ this prompt to reset the\n",
            "LLM’s context:\n",
            "“Ignore everything that we have discussed. Start\n",
            "over.”\n",
            "The “start over” idea helps produce a complete reset of the\n",
            "context.\n",
            "5) Consequences: One consequence of this pattern is that\n",
            "it may inadvertently wipe out patterns applied to the con-\n",
            "versation that the user is unaware of. For example, if an \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 16: \n",
            "\n",
            "organization injects a series of helpful patterns into the s tart of\n",
            "a conversation, the user may not be aware of these patterns an d\n",
            "remove them through a reset of the context. This reset could\n",
            "potentially eliminate helpful capabilities of the LLM, whi le\n",
            "not making it obvious that the user will lose this functional ity.\n",
            "A potential solution to this problem is to include in the prom pt\n",
            "a request to explain what topics/instructions will potenti ally be\n",
            "lost before proceeding.\n",
            "Q. The Recipe Pattern\n",
            "1) Intent and Context: This pattern provides constraints to\n",
            "ultimately output a sequence of steps given some partially\n",
            "provided “ingredients” that must be conﬁgured in a sequence\n",
            "of steps to achieve a stated goal. It combines the T emplate,\n",
            "Alternative Approaches , and Reﬂection patterns.\n",
            "2) Motivation: Users often want an LLM to analyze a\n",
            "concrete sequence of steps or procedures to achieve a stated\n",
            "outcome. Typically, users generally know—or have an idea \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 16: \n",
            "\n",
            "of—what the end goal should look like and what “ingredients”\n",
            "belong in the prompt. However, they may not necessarily know\n",
            "the precise ordering of steps to achieve that end goal.\n",
            "For example, a user may want a precise speciﬁcation on how\n",
            "a piece of code should be implemented or automated, such as\n",
            "“create an Ansible playbook to ssh into a set of servers, copy\n",
            "text ﬁles from each server, spawn a monitoring process on\n",
            "each server, and then close the ssh connection to each server .\n",
            "In other words, this pattern represents a generalization of the\n",
            "example of “given the ingredients in my fridge, provide dinn er\n",
            "recipes.” A user may also want to specify a set number of\n",
            "alternative possibilities, such as “provide 3 different wa ys of\n",
            "deploying a web application to AWS using Docker containers\n",
            "and Ansible using step by step instructions”.\n",
            "3) Structure and Key Ideas: Fundamental contextual state-\n",
            "ments:\n",
            "Contextual Statements\n",
            "I would like to achieve X\n",
            "I know that I need to perform steps A,B,C \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 16: \n",
            "\n",
            "Provide a complete sequence of steps for me\n",
            "Fill in any missing steps\n",
            "Identify any unnecessary steps\n",
            "The ﬁrst statement “I would like to achieve X” focuses the\n",
            "LLM on the overall goal that the recipe needs to be built\n",
            "to achieve. The steps will be organized and completed to\n",
            "sequentially achieve the goal speciﬁed. The second stateme nt\n",
            "provides the partial list of steps that the user would like\n",
            "to include in the overall recipe. These serve as intermediat e\n",
            "waypoints for the path that the LLM is going to generate or\n",
            "constraints on the structure of the recipe. The next stateme nt\n",
            "in the pattern, “provide a complete sequence of steps for\n",
            "me”, indicates to the LLM that the goal is to provide a\n",
            "complete sequential ordering of steps. The “ﬁll in any missi ng\n",
            "steps” helps ensure that the LLM will attempt to complete\n",
            "the recipe without further follow-up by making some choices\n",
            "on the user’s behalf regarding missing steps, as opposed to \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 16: \n",
            "\n",
            "just stating additional information that is needed. Finall y, the\n",
            "last statement, “identify any unnecessary steps,” is usefu l in\n",
            "ﬂagging inaccuracies in the user’s original request so that the\n",
            "ﬁnal recipe is efﬁcient.\n",
            "4) Example Implementation: An example usage of this\n",
            "pattern in the context of deploying a software application t o\n",
            "the cloud is shown below:\n",
            "“I am trying to deploy an application to the cloud. I\n",
            "know that I need to install the necessary dependen-\n",
            "cies on a virtual machine for my application. I know\n",
            "that I need to sign up for an AWS account. Please\n",
            "provide a complete sequence of steps. Please ﬁll in\n",
            "any missing steps. Please identify any unnecessary\n",
            "steps.”\n",
            "Depending on the use case and constraints, “installing\n",
            "necessary dependencies on a virtual machine” may be an\n",
            "unnecessary step. For example, if the application is alread y\n",
            "packaged in a Docker container, the container could be de-\n",
            "ployed directly to the AWS Fargate Service, which does not \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 16: \n",
            "\n",
            "require any management of the underlying virtual machines.\n",
            "The inclusion of the “identify unnecessary steps” language\n",
            "will cause the LLM to ﬂag this issue and omit the steps from\n",
            "the ﬁnal recipe.\n",
            "5) Consequences: One consequence of the recipe pattern is\n",
            "that a user may not always have a well-speciﬁed description\n",
            "of what they would like to implement, construct, or design.\n",
            "Moreover, this pattern may introduce unwanted bias from the\n",
            "user’s initially selected steps so the LLM may try to ﬁnd a\n",
            "solution that incorporates them, rather than ﬂagging them a s\n",
            "unneeded. For example, an LLM may try to ﬁnd a solution\n",
            "that does install dependencies for a virtual machine, even i f\n",
            "there are solutions that do not require that. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 17: \n",
            "\n",
            "IV. R ELATED WORK\n",
            "Software patterns [10], [11] have been extensively studied\n",
            "and documented in prior work. Patterns are widely used in\n",
            "software engineering to express the intent of design struct ures\n",
            "in a way that is independent of implementation details. Patt erns\n",
            "provide a mental picture of the goals that the pattern is\n",
            "trying to achieve and the forces that it is trying to resolve.\n",
            "A key advantage of patterns is their composability, allowin g\n",
            "developers to build pattern sequences and pattern language s\n",
            "that can be used to address complex problems. Patterns have\n",
            "also been investigated in other domains, such as contract\n",
            "design for decentralized ledgers [17], [18].\n",
            "The importance of good prompt design with LLMs, such as\n",
            "ChatGPT, is well understood [19]–[28]. Previous studies ha ve\n",
            "examined the effect of prompt words on AI generative models.\n",
            "For example, Liu et al. [29] investigated how different\n",
            "prompt key words affect image generation and different char - \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 17: \n",
            "\n",
            "acteristics of images. Other work has explored using LLMs\n",
            "to generate visualizations [30]. Han et al. [31] researched\n",
            "strategies for designing prompts for classiﬁcation tasks. Other\n",
            "research has looked at boolean prompt design for literature\n",
            "queries [32]. Y et other work has speciﬁcally examined prompts\n",
            "for software and ﬁxing bugs [33].\n",
            "Our work is complementary to prior work by providing\n",
            "a structure for documenting, discussing, and reasoning abo ut\n",
            "prompts that can aid users in developing mental models for\n",
            "structuring prompts to solve common problems.\n",
            "The quality of the answers produced by LLMs, particuarly\n",
            "ChatGPT, has been assessed in a number of domains. For\n",
            "example, ChatGPT has been used to take the medical licensing\n",
            "exam with surprisingly good results [3]. The use of ChatGPT\n",
            "in Law School has also been explored [34]. Other papers have\n",
            "looked at its mathematical reasoning abilities [35]. As mor e\n",
            "domains are explored, we expect that domain-speciﬁc patter n \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 17: \n",
            "\n",
            "catalogs will be developed to share domain-speciﬁc problem\n",
            "solving prompt structures.\n",
            "V. C ONCLUDING REMARKS\n",
            "This paper presented a framework for documenting and\n",
            "applying a catalog of prompt patterns for large language\n",
            "models (LLMs), such as ChatGPT. These prompt patterns are\n",
            "analogous to software patterns and aim to provide reusable\n",
            "solutions to problems that users face when interacting with\n",
            "LLMs to perform a wide range of tasks. The catalog of prompt\n",
            "patterns captured via this framework (1) provides a structu red\n",
            "way of discussing prompting solutions, (2) identiﬁes patte rns\n",
            "in prompts, rather than focusing on speciﬁc prompt examples ,\n",
            "and (3) classiﬁes patterns so users are guided to more efﬁcie nt\n",
            "and effective interactions with LLMs.\n",
            "The following lessons learned were gleaned from our work\n",
            "on prompt patterns:\n",
            "• Prompt patterns signiﬁcantly enrich the capabilities that\n",
            "can be created in a conversational LLM . For example,\n",
            "prompts can lead to the generation of cybersecurity \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 17: \n",
            "\n",
            "games, complete with ﬁctitious terminal commands that\n",
            "have been run by an attacker stored in a .bash\n",
            "history\n",
            "ﬁle. As shown in Section III, larger and more complex\n",
            "capabilities can be created by combining prompt patterns,\n",
            "such as combining the Game Play and Visualization\n",
            "Generator patterns.\n",
            "• Documenting prompt patterns as a pattern catalog is\n",
            "useful, but insufﬁcient . Our experience indicates that\n",
            "much more work can be done in this area, both in terms\n",
            "of reﬁning and expanding the prompt patterns presented\n",
            "in this paper, as well as in exploring new and innovative\n",
            "ways of using LLMs. In particular, weaving the prompt\n",
            "patterns captured here as a pattern catalog into a more\n",
            "expression pattern language will help guide users of\n",
            "LLMs more effectively.\n",
            "• LLM Capabilities will evolve over time, likely necessitat-\n",
            "ing reﬁnement of patterns. As LLM capabilities change,\n",
            "some patterns may no longer be necessary, be obviated\n",
            "by different styles of interaction or conversation/sessio n \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 17: \n",
            "\n",
            "management approaches, or require enhancement to func-\n",
            "tion correctly. Continued work will be needed to docu-\n",
            "ment and catalog patterns that provide reusable solutions.\n",
            "• The prompt patterns are generalizable to many differ-\n",
            "ent domains. Although most of the patterns have been\n",
            "discussed in the context of software development, these\n",
            "same patterns are applicable in arbitrary domains, ranging\n",
            "from inﬁnite generation of stories for entertainment to\n",
            "educational games to explorations of topics.\n",
            "We hope that this paper inspires further research and de-\n",
            "velopment in this area that will help enhance prompt pattern\n",
            "design to create new and unexpected capabilities for conver -\n",
            "sational LLMs.\n",
            "REFERENCES\n",
            "[1] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von\n",
            "Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill et al. ,\n",
            "“On the opportunities and risks of foundation models,” arXiv preprint\n",
            "arXiv:2108.07258, 2021. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 17: \n",
            "\n",
            "[2] Y . Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, H. Lovenia,\n",
            "Z. Ji, T. Y u, W. Chung et al. , “A multitask, multilingual, multimodal\n",
            "evaluation of chatgpt on reasoning, hallucination, and int eractivity,”\n",
            "arXiv preprint arXiv:2302.04023 , 2023.\n",
            "[3] A. Gilson, C. Safranek, T. Huang, V . Socrates, L. Chi, R. A . Taylor,\n",
            "and D. Chartash, “How well does chatgpt do when taking the med ical\n",
            "licensing exams?” medRxiv, pp. 2022–12, 2022.\n",
            "[4] A. Carleton, M. H. Klein, J. E. Robert, E. Harper, R. K. Cun ningham,\n",
            "D. de Niz, J. T. Foreman, J. B. Goodenough, J. D. Herbsleb, I. O zkaya,\n",
            "and D. C. Schmidt, “Architecting the future of software engi neering,”\n",
            "Computer, vol. 55, no. 9, pp. 89–93, 2022.\n",
            "[5] “Github copilot · your ai pair programmer.” [Online]. Av ailable:\n",
            "https://github.com/features/copilot\n",
            "[6] O. Asare, M. Nagappan, and N. Asokan, “Is github’s copilo t as bad\n",
            "as humans at introducing vulnerabilities in code?” arXiv preprint\n",
            "arXiv:2204.04741, 2022. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 17: \n",
            "\n",
            "[7] H. Pearce, B. Ahmad, B. Tan, B. Dolan-Gavitt, and R. Karri , “Asleep at\n",
            "the keyboard? assessing the security of github copilot’s co de contribu-\n",
            "tions,” in 2022 IEEE Symposium on Security and Privacy (SP) . IEEE,\n",
            "2022, pp. 754–768.\n",
            "[8] J. Krochmalski, IntelliJ IDEA Essentials . Packt Publishing Ltd, 2014.\n",
            "[9] P . Liu, W. Y uan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-\n",
            "train, prompt, and predict: A systematic survey of promptin g methods\n",
            "in natural language processing,” ACM Computing Surveys, vol. 55, no. 9,\n",
            "pp. 1–35, 2023. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 18: \n",
            "\n",
            "[10] E. Gamma, R. Johnson, R. Helm, R. E. Johnson, and J. Vliss ides,\n",
            "Design patterns: elements of reusable object-oriented sof tware. Pearson\n",
            "Deutschland GmbH, 1995.\n",
            "[11] D. C. Schmidt, M. Stal, H. Rohnert, and F. Buschmann, Pattern-oriented\n",
            "software architecture, patterns for concurrent and networ ked objects .\n",
            "John Wiley & Sons, 2013.\n",
            "[12] OpenAI, “ChatGPT: Large-Scale Generative Language Mo dels for\n",
            "Automated Content Creation,” https://openai.com/blog/c hatgpt/, 2023,\n",
            "[Online; accessed 19-Feb-2023].\n",
            "[13] ——, “DALL·E 2: Creating Images from Text,”\n",
            "https://openai.com/dall-e-2/ , 2023, [Online; accessed 1 9-Feb-2023].\n",
            "[14] D. Zhou, N. Sch¨ arli, L. Hou, J. Wei, N. Scales, X. Wang, D . Schu-\n",
            "urmans, O. Bousquet, Q. Le, and E. Chi, “Least-to-most promp ting\n",
            "enables complex reasoning in large language models,” arXiv preprint\n",
            "arXiv:2205.10625, 2022.\n",
            "[15] J. Ellson, E. R. Gansner, E. Koutsoﬁos, S. C. North, and G . Woodhull,\n",
            "“Graphviz and dynagraph—static and dynamic graph drawing t ools,” \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 18: \n",
            "\n",
            "Graph drawing software , pp. 127–148, 2004.\n",
            "[16] S. Owen, “Building a virtual machine inside a javascrip t library,”\n",
            "https://www.engraved.blog/building-a-virtual-machine-inside/, 2022,\n",
            "accessed: 2023-02-20.\n",
            "[17] P . Zhang, J. White, D. C. Schmidt, and G. Lenz, “Applying\n",
            "software patterns to address interoperability in blockcha in-based\n",
            "healthcare apps,” CoRR, vol. abs/1706.03700, 2017. [Online]. Available:\n",
            "http://arxiv.org/abs/1706.03700\n",
            "[18] X. Xu, C. Pautasso, L. Zhu, Q. Lu, and I. Weber, “A pattern collection\n",
            "for blockchain-based applications,” in Proceedings of the 23rd European\n",
            "Conference on Pattern Languages of Programs , 2018, pp. 1–20.\n",
            "[19] E. A. van Dis, J. Bollen, W. Zuidema, R. van Rooij, and C. L . Bockting,\n",
            "“Chatgpt: ﬁve priorities for research,” Nature, vol. 614, no. 7947, pp.\n",
            "224–226, 2023.\n",
            "[20] L. Reynolds and K. McDonell, “Prompt programming for la rge language\n",
            "models: Beyond the few-shot paradigm,” CoRR, vol. abs/2102.07350, \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 18: \n",
            "\n",
            "2021. [Online]. Available: https://arxiv.org/abs/2102. 07350\n",
            "[21] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. H. Chi, Q. Le,\n",
            "and D. Zhou, “Chain of thought prompting elicits reasoning i n\n",
            "large language models,” CoRR, vol. abs/2201.11903, 2022. [Online].\n",
            "Available: https://arxiv.org/abs/2201.11903\n",
            "[22] J. Wei, Y . Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borge aud,\n",
            "D. Y ogatama, M. Bosma, D. Zhou, D. Metzler, E. H. Chi,\n",
            "T. Hashimoto, O. Vinyals, P . Liang, J. Dean, and W. Fedus, “Em ergent\n",
            "abilities of large language models,” 2022. [Online]. Avail able:\n",
            "https://arxiv.org/abs/2206.07682\n",
            "[23] Y . Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis, H. Ch an, and\n",
            "J. Ba, “Large language models are human-level prompt engine ers,”\n",
            "2022. [Online]. Available: https://arxiv.org/abs/2211. 01910\n",
            "[24] T. Shin, Y . Razeghi, R. L. L. IV , E. Wallace, and S. Singh,\n",
            "“Autoprompt: Eliciting knowledge from language models wit h\n",
            "automatically generated prompts,” CoRR, vol. abs/2010.15980, 2020. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 18: \n",
            "\n",
            "[Online]. Available: https://arxiv.org/abs/2010.15980\n",
            "[25] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sut skever,\n",
            "“Language models are unsupervised multitask learners,” 20 19.\n",
            "[26] D. Zhou, N. Sch¨ arli, L. Hou, J. Wei, N. Scales, X. Wang,\n",
            "D. Schuurmans, C. Cui, O. Bousquet, Q. Le, and E. Chi, “Least- to-\n",
            "most prompting enables complex reasoning in large language models,”\n",
            "2022. [Online]. Available: https://arxiv.org/abs/2205. 10625\n",
            "[27] J. Jung, L. Qin, S. Welleck, F. Brahman, C. Bhagavatula, R. L.\n",
            "Bras, and Y . Choi, “Maieutic prompting: Logically consiste nt\n",
            "reasoning with recursive explanations,” 2022. [Online]. A vailable:\n",
            "https://arxiv.org/abs/2205.11822\n",
            "[28] S. Arora, A. Narayan, M. F. Chen, L. Orr, N. Guha,\n",
            "K. Bhatia, I. Chami, and C. Re, “Ask me anything: A\n",
            "simple strategy for prompting language models,” in International\n",
            "Conference on Learning Representations , 2023. [Online]. Available:\n",
            "https://openreview.net/forum?id=bhUPJnS2g0X \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 18: \n",
            "\n",
            "[29] V . Liu and L. B. Chilton, “Design guidelines for prompt e ngineering\n",
            "text-to-image generative models,” in Proceedings of the 2022 CHI\n",
            "Conference on Human Factors in Computing Systems , 2022, pp. 1–23.\n",
            "[30] P . Maddigan and T. Susnjak, “Chat2vis: Generating data visualisations\n",
            "via natural language using chatgpt, codex and gpt-3 large la nguage\n",
            "models,” arXiv preprint arXiv:2302.02094 , 2023.\n",
            "[31] X. Han, W. Zhao, N. Ding, Z. Liu, and M. Sun, “Ptr: Prompt t uning\n",
            "with rules for text classiﬁcation,” AI Open , vol. 3, pp. 182–192, 2022.\n",
            "[32] S. Wang, H. Scells, B. Koopman, and G. Zuccon, “Can chatg pt write\n",
            "a good boolean query for systematic review literature searc h?” arXiv\n",
            "preprint arXiv:2302.03495 , 2023.\n",
            "[33] C. S. Xia and L. Zhang, “Conversational automated progr am repair,”\n",
            "arXiv preprint arXiv:2301.13246 , 2023.\n",
            "[34] J. H. Choi, K. E. Hickman, A. Monahan, and D. Schwarcz, “C hatgpt\n",
            "goes to law school,” Available at SSRN , 2023. \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Page 18: \n",
            "\n",
            "[35] S. Frieder, L. Pinchetti, R.-R. Grifﬁths, T. Salvatori , T. Lukasiewicz,\n",
            "P . C. Petersen, A. Chevalier, and J. Berner, “Mathematical c apabilities\n",
            "of chatgpt,” arXiv preprint arXiv:2301.13867 , 2023. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loader = PyPDFLoader(os.path.join(PATH, os.listdir(PATH)[1]))\n",
        "documents = loader.load()\n",
        "\n",
        "# split the docs\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(len(split_docs))\n",
        "for doc in split_docs:\n",
        "    print('-'*100)\n",
        "    print(f\"Page {doc.metadata['page']}: \\n\")\n",
        "    print(f\"{doc.page_content} \\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "86201bb2",
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Chroma' object has no attribute 'persist'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m embedding_model = OpenAIEmbeddings(\n\u001b[32m      2\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-3-small\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     openai_api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLLM\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      4\u001b[39m     openai_api_base=\u001b[33m\"\u001b[39m\u001b[33mhttps://openrouter.ai/api/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m db = Chroma.from_documents(\n\u001b[32m      8\u001b[39m     documents=split_docs[\u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m],\n\u001b[32m      9\u001b[39m     embedding=embedding_model,\n\u001b[32m     10\u001b[39m     persist_directory=os.path.join(PATH, \u001b[33m\"\u001b[39m\u001b[33mchroma_db\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpersist\u001b[49m()\n",
            "\u001b[31mAttributeError\u001b[39m: 'Chroma' object has no attribute 'persist'"
          ]
        }
      ],
      "source": [
        "embedding_model = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    openai_api_key=os.getenv(\"LLM\"),\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "db = Chroma.from_documents(\n",
        "    documents=split_docs[0:1],\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=os.path.join(PATH, \"chroma_db\")\n",
        ")\n",
        "db.persist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a52b213",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ed423ce4",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Complete RAG Implementation with Issue Fixes\n",
        "Addresses: API configuration, embeddings setup, database persistence, and full retrieval+generation pipeline\n",
        "\"\"\"\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "PATH = './docs'\n",
        "LLM_KEY = os.getenv(\"LLM\")  # Ensure this is set in .env\n",
        "\n",
        "if not LLM_KEY:\n",
        "    raise ValueError(\"LLM environment variable not set. Check your .env file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "58143209",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ignoring wrong pointing object 2 65536 (offset 0)\n",
            "Ignoring wrong pointing object 34 65536 (offset 0)\n",
            "Ignoring wrong pointing object 92 65536 (offset 0)\n",
            "Ignoring wrong pointing object 145 65536 (offset 0)\n",
            "Ignoring wrong pointing object 206 65536 (offset 0)\n",
            "Ignoring wrong pointing object 274 65536 (offset 0)\n",
            "Ignoring wrong pointing object 330 65536 (offset 0)\n",
            "Ignoring wrong pointing object 372 65536 (offset 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 803 pages\n",
            "Split into 3329 chunks\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "documents = []\n",
        "for file_path in os.listdir(PATH):\n",
        "    if file_path.endswith('.pdf'):\n",
        "        joined_path = os.path.join(PATH, file_path)\n",
        "        loader = PyPDFLoader(joined_path)\n",
        "        documents.extend(loader.load()) \n",
        "\n",
        "print(f\"Loaded {len(documents)} pages\")\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Split into {len(split_docs)} chunks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7842edc2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store created with 3329 documents\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# STEP 2: CREATE EMBEDDINGS AND VECTOR STORE\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    api_key=LLM_KEY,\n",
        "    base_url=\"https://openrouter.ai/api/v1\"  # ISSUE #5 FIX: Use base_url instead of openai_api_base\n",
        ")\n",
        "\n",
        "chroma_db_path = os.path.join(PATH, \"chroma_db\")\n",
        "db = Chroma.from_documents(\n",
        "    documents=split_docs,  # ISSUE #6 FIX: Index all chunks\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=chroma_db_path\n",
        ")\n",
        "print(f\"Vector store created with {len(split_docs)} documents\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1ac898ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 3: CREATE RETRIEVER\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 5})  # Retrieve top 3 most relevant chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6a34aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 4: SETUP LLM FOR GENERATION\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    api_key=LLM_KEY,\n",
        "    base_url=\"https://openrouter.ai/api/v1\",  # Remove if using OpenAI directly\n",
        "    temperature=0.7\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e75f17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 5: CRAG SETUP\n",
        "import json\n",
        "\n",
        "rag_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a helpful assistant that answers questions based on the provided context.\n",
        "\n",
        "## CONTEXT:\n",
        "{context}\n",
        "\n",
        "## QUESTION:\n",
        "{question}\n",
        "\n",
        "## ANSWER:\n",
        "Provide a clear, concise answer based on the context above. If the context doesn't contain the answer, say so.\n",
        "Include the sources of the used context in the answer.\n",
        "\"\"\",\n",
        "    input_variables=[\"context\", \"question\"],\n",
        ")\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    \"\"\"Format retrieved documents for the prompt.\"\"\"\n",
        "    context = []\n",
        "    for retreived_doc in docs:\n",
        "        content = retreived_doc.page_content\n",
        "        source = retreived_doc.metadata[\"source\"]\n",
        "        context.append({\"source\": source, \"content\": content})\n",
        "    return json.dumps(context)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever | format_docs,  # Retrieve and format documents\n",
        "        \"question\": RunnablePassthrough(),  # Pass through the user question\n",
        "    }\n",
        "    | rag_prompt  # Format the prompt\n",
        "    | llm  # Send to LLM\n",
        "    | StrOutputParser()  # Parse the response as string\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce25fbcf",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e8df5a59",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A: Qualitätsmanagement ist das Management von systematischen Planungs- und Steuerungsprozessen in einem Unternehmen, um Produkte von hoher Qualität zu liefern, die die Anforderungen der Kunden erfüllen. Es umfasst aufeinander abgestimmte Tätigkeiten zum Leiten und Lenken einer Organisation bezüglich der Qualität. Das Qualitätsmanagementsystem (QM-System) ist das Managementsystem zur Leitung und Lenkung einer Organisation hinsichtlich der Qualität, was die Festlegung der Qualitätspolitik, Qualitätsziele, Qualitätsplanung und Qualitätslenkung beinhaltet.\n",
            "\n",
            "Sources:\n",
            "- Grundlagen Qualitätsmanagement\n",
            "- DIN EN ISO 9000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 8: TEST THE RAG PIPELINE\n",
        "# ============================================================================\n",
        "query = \"was ist qualitätsmanagement?\"\n",
        "answer = rag_chain.invoke(query)\n",
        "\n",
        "print(f\"A: {answer}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "agents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
